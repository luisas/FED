{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5baa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
 {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e6407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef28f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a418e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d2789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2eddd3",
   "metadata": {},
   "source": [
    "## Old way - dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new dataset\n",
    "dataset_197k = []\n",
    "NEW_SEQUENCE_LENGTH = 196_608\n",
    "max_steps = 2\n",
    "\n",
    "for i, batch in tqdm(enumerate(human_dataset)):\n",
    "    batch_197k = {}\n",
    "    # 1 from the sequence 131k get the sequence 197k\n",
    "    interval_test = get_interval_from_sequence(batch[\"sequence\"])\n",
    "    sequence_197k = one_hot_encode(fasta_extractor.extract(interval_test.resize(NEW_SEQUENCE_LENGTH)))\n",
    "    batch_197k[\"sequence\"] = tf.constant(sequence_197k[np.newaxis])\n",
    "    \n",
    "    # add same real targets\n",
    "    batch_197k[\"target\"] = batch[\"target\"]\n",
    "    dataset_197k.append(batch_197k)\n",
    "    if max_steps is not None and i > max_steps:\n",
    "        break\n",
    "\n",
    "file = os.path.join(outputdir,'new_dataset_197k_valid.h5')\n",
    "\n",
    "# Step 2\n",
    "with open(file, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(dataset_197k, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_197k[1][\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59878f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGHT = 393_216\n",
    "## pad the sequence with Ns (anyways ignored by the model)\n",
    "def pad_one_hot(sequence_one_hot, NEW_SIZE):\n",
    "    ADD_ENDS = int((NEW_SIZE - sequence_one_hot.shape[0])/2)\n",
    "    pad_zero = np.tile(np.array([0., 0., 0., 0.]), (ADD_ENDS, 1))\n",
    "    padded_left = np.append(pad_zero,sequence_one_hot, axis=0)\n",
    "    pad_sequence = np.append(padded_left,pad_zero, axis=0)\n",
    "    return(pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ed62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try predictions\n",
    "def evaluate_model_all_sequences_mod(model, dataset, head, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    \n",
    "    def predict(x):\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "    \n",
    "    i = 0 \n",
    "    for i, batch in enumerate(dataset_197k): \n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        i = i+1\n",
    "        prediction = predict(batch['sequence'])\n",
    "        metric.update_state(batch['target'], prediction)\n",
    "\n",
    "    return metric.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca72198",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_human = evaluate_model_all_sequences_mod(model,\n",
    "                               dataset=dataset_197k[0:1],\n",
    "                               head='human',\n",
    "                               max_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(metrics_human[\"PearsonR\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_human"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb411e",
   "metadata": {},
   "source": [
    "## Refined creation with tfr records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e960dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata\n",
    "metadata_human_197k = get_metadata(\"human\")\n",
    "metadata_human_197k['seq_length'] = NEW_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aef53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, head):\n",
    "    padded_sequence = pad_one_hot(x, SEQUENCE_LENGHT)[np.newaxis]\n",
    "    predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "    return tf.convert_to_tensor(predictions, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d292fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:05, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': <tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0.]]], dtype=float32)>,\n",
       " 'target': <tf.Tensor: shape=(1, 896, 5313), dtype=float32, numpy=\n",
       " array([[[0.09924316, 0.0927124 , 0.01834106, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.11126709, 0.1685791 , 0.03396606, ..., 0.        ,\n",
       "          0.984375  , 0.        ],\n",
       "         [0.14318848, 0.23217773, 0.01850891, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00662994, 0.01672363, 0.00756454, ..., 0.01852417,\n",
       "          0.11566162, 0.        ],\n",
       "         [0.00411224, 0.00155735, 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.06958008, 0.03845215, 0.04312134, ..., 0.        ,\n",
       "          0.        , 0.        ]]], dtype=float32)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test entry \n",
    "for i, batch in tqdm(enumerate(human_dataset)):\n",
    "    print(i)\n",
    "    first_dataset_entry = batch\n",
    "    break\n",
    "#interval_test = get_interval_from_sequence(first_dataset_entry)\n",
    "first_dataset_entry\n",
    "#target_one = predict(first_dataset_entry[\"sequence\"], \"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6c6f9",
   "metadata": {},
   "source": [
    "### Try to add targets into tfr record (serialized!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d02605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_one = first_dataset_entry[\"sequence\"]\n",
    "sequence_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588dbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_one = predict(np.squeeze(first_dataset_entry[\"sequence\"]), \"human\")\n",
    "target_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "10e86723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _array_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.numpy().tobytes()]))\n",
    "\n",
    "def serialize_example(sequence, target):\n",
    "\n",
    "    feature = {\n",
    "      'sequence':  _array_feature(sequence),\n",
    "      'target':  _array_feature(target),\n",
    "    }\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "def tf_serialize_example(sequence, target):\n",
    "    tf_string = tf.py_function(serialize_example,(sequence, target), tf.string) \n",
    "    return tf.reshape(tf_string, ()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dd2c8f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for features in features_dataset:\n",
    "        yield serialize_example(*features)"
   ]
  } 





 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
