{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed624904",
   "metadata": {},
   "source": [
    "# Enformer human validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbf0ab",
   "metadata": {},
   "source": [
    "### Load  pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba173e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 09:53:47.387181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-26 09:53:47.387207: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import joblib\n",
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import os\n",
    "import enformer \n",
    "from tqdm import tqdm\n",
    "import importlib.util\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c01c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils.py as module\n",
    "spec_utils = importlib.util.spec_from_file_location(\"enformer\", os.path.join(os.getcwd() ,\"utils.py\"))\n",
    "utils = importlib.util.module_from_spec(spec_utils)\n",
    "spec_utils.loader.exec_module(utils)\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3113d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import enformer.py as module\n",
    "spec = importlib.util.spec_from_file_location(\"enformer\", os.path.join(os.getcwd() ,\"enformer.py\"))\n",
    "enformer = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(enformer)\n",
    "from enformer import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6254a",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f0900f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Faidx(\"../../../../data/FED/hg38.fa\")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\n",
    "model_path = 'https://tfhub.dev/deepmind/enformer/1'\n",
    "datadir = \"../../../../data/FED\"\n",
    "fasta_file = os.path.join(datadir, \"hg38.fa\")\n",
    "human_sequences = os.path.join(datadir, \"data_human_sequences.bed\")\n",
    "pyfaidx.Faidx(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91386fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 09:53:55.510835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-26 09:53:55.510854: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-26 09:53:55.510868: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (luisasantus-HP-EliteDesk-800-G5-TWR): /proc/driver/nvidia/version does not exist\n",
      "2022-01-26 09:53:55.511115: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Enformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e380ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_extractor = FastaStringExtractor(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0bc8a25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196608.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "393216/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2f5d7",
   "metadata": {},
   "source": [
    "### Check tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0b5360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genome</th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>clip</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF833POA</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:cerebellum male adult (27 years) and mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF110QGM</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:frontal cortex male adult (27 years) and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF880MKD</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:chorion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF463ZLQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:Ishikawa treated with 0.02% dimethyl sul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF890OGQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:GM03348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>5308</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14239</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:epithelioid sarcoma cell line:HS-ES-2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>5309</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14240</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:squamous cell lung carcinoma cell line:RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>5310</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14241</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:gastric cancer cell line:GSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>5311</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14244</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:carcinoid cell line:NCI-H727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>5312</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14245</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:lung adenocarcinoma, papillary cell line:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5313 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  genome   identifier  \\\n",
       "0         0       0  ENCFF833POA   \n",
       "1         1       0  ENCFF110QGM   \n",
       "2         2       0  ENCFF880MKD   \n",
       "3         3       0  ENCFF463ZLQ   \n",
       "4         4       0  ENCFF890OGQ   \n",
       "...     ...     ...          ...   \n",
       "5308   5308       0    CNhs14239   \n",
       "5309   5309       0    CNhs14240   \n",
       "5310   5310       0    CNhs14241   \n",
       "5311   5311       0    CNhs14244   \n",
       "5312   5312       0    CNhs14245   \n",
       "\n",
       "                                                   file  clip  scale sum_stat  \\\n",
       "0     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "1     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "2     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "3     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "4     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "...                                                 ...   ...    ...      ...   \n",
       "5308  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5309  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5310  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5311  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5312  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "\n",
       "                                            description  \n",
       "0     DNASE:cerebellum male adult (27 years) and mal...  \n",
       "1     DNASE:frontal cortex male adult (27 years) and...  \n",
       "2                                         DNASE:chorion  \n",
       "3     DNASE:Ishikawa treated with 0.02% dimethyl sul...  \n",
       "4                                         DNASE:GM03348  \n",
       "...                                                 ...  \n",
       "5308        CAGE:epithelioid sarcoma cell line:HS-ES-2R  \n",
       "5309  CAGE:squamous cell lung carcinoma cell line:RE...  \n",
       "5310                  CAGE:gastric cancer cell line:GSS  \n",
       "5311                  CAGE:carcinoid cell line:NCI-H727  \n",
       "5312  CAGE:lung adenocarcinoma, papillary cell line:...  \n",
       "\n",
       "[5313 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download targets from Basenji2 dataset \n",
    "# Cite: Kelley et al Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\n",
    "targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
    "df_targets = pd.read_csv(targets_txt, sep='\\t')\n",
    "df_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9540639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Supplementary Table 1', 'Supplementary Table 2', 'Supplementary Table 3']\n"
     ]
    }
   ],
   "source": [
    "suppl = pd.ExcelFile(os.path.join(datadir, \"enformer_suppl.xlsx\"))\n",
    "print(suppl.sheet_names)\n",
    "suppl_human = suppl.parse(suppl.sheet_names[1])\n",
    "suppl_mouse = suppl.parse(suppl.sheet_names[2])\n",
    "suppl_human[\"organism\"] = \"human\"\n",
    "suppl_mouse[\"organism\"] = \"mouse\"\n",
    "frames = [suppl_human, suppl_mouse]\n",
    "suppl_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c07dcd",
   "metadata": {},
   "source": [
    "## Example predict one sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d5f950b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence):\n",
    "    return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
    "\n",
    "SEQUENCE_LENGHT = 393216\n",
    "#REAL_SEQUENCE_LENGTH = SEQUENCE_LENGHT/2\n",
    "#ADD_ENDS = int((SEQUENCE_LENGHT - REAL_SEQUENCE_LENGTH)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f2c46cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393216, 4)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pad the sequence with Ns (anyways ignored by the model)\n",
    "def pad_one_hot(sequence_one_hot, NEW_SIZE):\n",
    "    ADD_ENDS = int((NEW_SIZE - sequence_one_hot.shape[0])/2)\n",
    "    pad_zero = np.tile(np.array([0., 0., 0., 0.]), (ADD_ENDS, 1))\n",
    "    padded_left = np.append(pad_zero,sequence_one_hot, axis=0)\n",
    "    pad_sequence = np.append(padded_left,pad_zero, axis=0)\n",
    "    return(pad_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917fd13",
   "metadata": {},
   "source": [
    "### compute score (how well predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b395ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO \n",
    "1 - retrieve the 197k sequence instead o 131k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a615e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dataset = get_dataset('human', 'valid').batch(1).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25efdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences(model, dataset, head, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    print(\"Metric dictionary created\")\n",
    "    \n",
    "    @tf.function\n",
    "    def predict(x):\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)['human']\n",
    "        return predictions\n",
    "    print(\"Predict funciton loaded\")\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(dataset)):\n",
    "\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        metric.update_state(batch['target'], predict(batch['sequence']))\n",
    "        #metric.update_state(batch['target'], batch['target'])\n",
    "        print(i)\n",
    "        print(batch)\n",
    "\n",
    "    return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "145795ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0829835 , 0.06613109, 0.0496952 , ..., 0.00328913,\n",
       "         0.0118176 , 0.00945621],\n",
       "        [0.08675303, 0.06505437, 0.045567  , ..., 0.00316417,\n",
       "         0.01133935, 0.00850564],\n",
       "        [0.11366496, 0.07915953, 0.05737301, ..., 0.01192076,\n",
       "         0.04589322, 0.04694396],\n",
       "        ...,\n",
       "        [0.27100125, 0.19733842, 0.10441186, ..., 0.00362802,\n",
       "         0.0153653 , 0.00943798],\n",
       "        [0.24782476, 0.2126574 , 0.10856232, ..., 0.00323784,\n",
       "         0.01595465, 0.01030887],\n",
       "        [0.2845043 , 0.27189302, 0.13506007, ..., 0.0034502 ,\n",
       "         0.01703565, 0.01312567]]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(batch[\"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ddb14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric dictionary created\n",
      "Predict funciton loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:07, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_3930890/2071429785.py\", line 8, in predict  *\n        sequence_one_hot = one_hot_encode(fasta_extractor.extract(x.resize(393216)))\n\n    AttributeError: 'Tensor' object has no attribute 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3930890/2277063094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate model on first ten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Right now it evaluates the whole model and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m metrics_human = evaluate_model_all_sequences(model,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3930890/2071429785.py\u001b[0m in \u001b[0;36mevaluate_model_all_sequences\u001b[0;34m(model, dataset, head, max_steps)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#metric.update_state(batch['target'], batch['target'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_3930890/2071429785.py\", line 8, in predict  *\n        sequence_one_hot = one_hot_encode(fasta_extractor.extract(x.resize(393216)))\n\n    AttributeError: 'Tensor' object has no attribute 'resize'\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on first ten \n",
    "# Right now it evaluates the whole model and \n",
    "metrics_human = evaluate_model_all_sequences(model,\n",
    "                               dataset=get_dataset('human', 'valid').batch(1).prefetch(2),\n",
    "                               head='human',\n",
    "                               max_steps=1)\n",
    "print('')\n",
    "print({k: v.numpy().mean() for k, v in metrics_human.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156e0f5",
   "metadata": {},
   "source": [
    "#### Distributions of pearson correlation coefficients per assay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb53e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the values are in order of assay (TODO check) \n",
    "assay_list = list(suppl_df[\"assay_type\"])\n",
    "pearson_per_assay = list(metrics_human[\"PearsonR\"].numpy())\n",
    "data_tuples = list(zip(assay_list,pearson_per_assay))\n",
    "df_pearson_assay = pd.DataFrame(data_tuples, columns=['assay','pearson'])\n",
    "df = df.astype({\"assay\": str, \"pearson\": float})\n",
    "df_pearson_assay[\"pearson\"]\n",
    "df = df_pearson_assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90165edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "# Initialize the FacetGrid object\n",
    "g = sns.FacetGrid(df, row=\"assay\", hue=\"assay\", aspect=15,  height = .5, palette=\"mako\")\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"pearson\",\n",
    "      bw_adjust=.5, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"pearson\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "g.map(label, \"pearson\")\n",
    "g.figure.subplots_adjust(hspace=0)\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)\n",
    "g.set(xlim = (0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c221d",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d57c3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset('mouse', 'train').batch(1).repeat()\n",
    "max_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c04e7c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:16, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'sequence': <tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
      "array([[[0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.]]], dtype=float32)>, 'target': <tf.Tensor: shape=(1, 896, 1643), dtype=float32, numpy=\n",
      "array([[[0.00774384, 0.06262207, 0.0579834 , ..., 1.1318359 ,\n",
      "         0.        , 0.6035156 ],\n",
      "        [0.02897644, 0.04907227, 0.12213135, ..., 0.00302887,\n",
      "         1.9921875 , 0.09564209],\n",
      "        [0.05709839, 0.08172607, 0.07495117, ..., 0.9848633 ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.0199585 , 0.0397644 , 0.01802063, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.01231384, 0.0163269 , 0.01808167, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.0050621 , 0.06262207, 0.01885986, ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)>}\n",
      "1\n",
      "{'sequence': <tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.]]], dtype=float32)>, 'target': <tf.Tensor: shape=(1, 896, 1643), dtype=float32, numpy=\n",
      "array([[[0.02494812, 0.31591797, 0.23632812, ..., 0.        ,\n",
      "         0.        , 0.9921875 ],\n",
      "        [0.03430176, 0.4104004 , 0.18664551, ..., 0.48339844,\n",
      "         2.1171875 , 0.        ],\n",
      "        [0.14172363, 0.4194336 , 0.17932129, ..., 1.0244141 ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.03875732, 0.02095032, 0.0670166 , ..., 0.48291016,\n",
      "         0.09124756, 0.10168457],\n",
      "        [0.07434082, 0.07226562, 0.0559082 , ..., 0.6855469 ,\n",
      "         0.94628906, 0.        ],\n",
      "        [0.08093262, 0.0848999 , 0.08843994, ..., 0.        ,\n",
      "         1.0175781 , 1.9013672 ]]], dtype=float32)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:16,  8.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in tqdm(enumerate(dataset)):\n",
    "        mybatch = batch \n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        print(i)\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9ddbcf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': <tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
       " array([[[0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.]]], dtype=float32)>,\n",
       " 'target': <tf.Tensor: shape=(1, 896, 1643), dtype=float32, numpy=\n",
       " array([[[0.00814056, 0.02476501, 0.06027222, ..., 0.        ,\n",
       "          0.9165039 , 1.0214844 ],\n",
       "         [0.03747559, 0.03271484, 0.0949707 , ..., 1.4677734 ,\n",
       "          0.6796875 , 1.9335938 ],\n",
       "         [0.05706787, 0.07159424, 0.11590576, ..., 0.        ,\n",
       "          1.0380859 , 1.4941406 ],\n",
       "         ...,\n",
       "         [0.05126953, 0.05950928, 0.07971191, ..., 0.59228516,\n",
       "          0.26757812, 0.        ],\n",
       "         [0.04214478, 0.11450195, 0.12561035, ..., 0.97314453,\n",
       "          1.3828125 , 0.98339844],\n",
       "         [0.17272949, 0.14013672, 0.07116699, ..., 0.        ,\n",
       "          0.        , 0.99658203]]], dtype=float32)>}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2bf189",
   "metadata": {},
   "outputs": [],
   "source": [
    "mybatch[\"target\"].numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4d3b5",
   "metadata": {},
   "source": [
    "### Retrieve real values matched with sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8ea04b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': <tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
       " array([[[0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.]]], dtype=float32)>,\n",
       " 'target': <tf.Tensor: shape=(1, 896, 1643), dtype=float32, numpy=\n",
       " array([[[0.00814056, 0.02476501, 0.06027222, ..., 0.        ,\n",
       "          0.9165039 , 1.0214844 ],\n",
       "         [0.03747559, 0.03271484, 0.0949707 , ..., 1.4677734 ,\n",
       "          0.6796875 , 1.9335938 ],\n",
       "         [0.05706787, 0.07159424, 0.11590576, ..., 0.        ,\n",
       "          1.0380859 , 1.4941406 ],\n",
       "         ...,\n",
       "         [0.05126953, 0.05950928, 0.07971191, ..., 0.59228516,\n",
       "          0.26757812, 0.        ],\n",
       "         [0.04214478, 0.11450195, 0.12561035, ..., 0.97314453,\n",
       "          1.3828125 , 0.98339844],\n",
       "         [0.17272949, 0.14013672, 0.07116699, ..., 0.        ,\n",
       "          0.        , 0.99658203]]], dtype=float32)>}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a3acec48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../../data/FED/data_human_sequences.bed'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_sequences"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
