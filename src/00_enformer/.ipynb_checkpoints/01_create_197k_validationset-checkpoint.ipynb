{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1d97e9",
   "metadata": {},
   "source": [
    "# Create validation dataset 197k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa379304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import joblib\n",
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import os\n",
    "import enformer \n",
    "from tqdm import tqdm\n",
    "import importlib.util\n",
    "import inspect\n",
    "from typing import Any, Callable, Dict, Optional, Text, Union, Iterable\n",
    "import attention_module\n",
    "import numpy as np\n",
    "import sonnet as snt\n",
    "import h5py\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d539019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../../../../data/FED\"\n",
    "human_sequences = os.path.join(datadir, \"data_human_sequences.bed\")\n",
    "outputdir = os.path.join(datadir, \"hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849f05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for search (can be improved! quite slow)\n",
    "#human_validation_dict = {}\n",
    "#for interval in interval_list: \n",
    "#    sequence = one_hot_encode(fasta_extractor.extract(interval))\n",
    "#    human_validation_dict[interval] = sequence\n",
    "    \n",
    "# -------- save\n",
    "enformer_dict_file = os.path.join(outputdir,'00_enformer_dict_seqs.h5')\n",
    "#with open(enformer_dict_file, 'wb') as config_dictionary_file:\n",
    "#    pickle.dump(human_validation_dict, config_dictionary_file)\n",
    "    \n",
    "# -------- read -------\n",
    "with open(enformer_dict_file, 'rb') as config_dictionary_file:\n",
    "    human_validation_dict = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b0796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e11a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interval_from_sequence(sequence, human_validation_dict=human_validation_dict): \n",
    "    for interval, sequence in human_validation_dict.items():\n",
    "        if np.allclose(sequence,first_dataset_entry):\n",
    "            return(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new dataset\n",
    "dataset_197k = []\n",
    "NEW_SEQUENCE_LENGTH = 196_608\n",
    "max_steps = 10\n",
    "\n",
    "for i, batch in tqdm(enumerate(human_dataset)):\n",
    "    batch_197k = {}\n",
    "    # 1 from the sequence 131k get the sequence 197k\n",
    "    interval_test = get_interval_from_sequence(batch[\"sequence\"])\n",
    "    sequence_197k = one_hot_encode(fasta_extractor.extract(interval_test.resize(NEW_SEQUENCE_LENGTH)))\n",
    "    batch_197k[\"sequence\"] = tf.Variable(sequence_197k[np.newaxis])\n",
    "    \n",
    "    # add same real targets\n",
    "    batch_197k[\"target\"] = batch[\"target\"]\n",
    "    dataset_197k.append(batch_197k)\n",
    "    if max_steps is not None and i > max_steps:\n",
    "        break\n",
    "\n",
    "        \n",
    "# ------ Save\n",
    "file = os.path.join(outputdir,'new_dataset_197k_valid.h5')\n",
    "# Step 2\n",
    "with open(file, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(dataset_197k, config_dictionary_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
