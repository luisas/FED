{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed624904",
   "metadata": {},
   "source": [
    "# Enformer human validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbf0ab",
   "metadata": {},
   "source": [
    "### Load  pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba173e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import joblib\n",
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import os\n",
    "import enformer \n",
    "from tqdm import tqdm\n",
    "import importlib.util\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55c46685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import enformer.py as module\n",
    "spec = importlib.util.spec_from_file_location(\"enformer\", os.path.join(os.getcwd() ,\"enformer.py\"))\n",
    "enformer = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(enformer)\n",
    "from enformer import * \n",
    "\n",
    "# import utils.py as module\n",
    "spec_utils = importlib.util.spec_from_file_location(\"enformer\", os.path.join(os.getcwd() ,\"utils.py\"))\n",
    "utils = importlib.util.module_from_spec(spec_utils)\n",
    "spec.loader.exec_module(utils)\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6254a",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7f0900f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\n",
    "model_path = 'https://tfhub.dev/deepmind/enformer/1'\n",
    "datadir = \"../../../../data/FED\"\n",
    "fasta_file = os.path.join(datadir, \"hg38.fa\")\n",
    "human_sequences = os.path.join(datadir, \"data_human_sequences.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8efd7130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Faidx(\"../../../../data/FED/hg38.fa\")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyfaidx.Faidx(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "413d374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enformer:\n",
    "\n",
    "    def __init__(self, tfhub_url):\n",
    "        self._model = hub.load(tfhub_url).model\n",
    "\n",
    "    def predict_on_batch(self, inputs):\n",
    "        predictions = self._model.predict_on_batch(inputs)\n",
    "        return {k: v.numpy() for k, v in predictions.items()}\n",
    "\n",
    "    @tf.function\n",
    "    def contribution_input_grad(self, input_sequence,\n",
    "                                  target_mask, output_head='human'):\n",
    "        input_sequence = input_sequence[tf.newaxis]\n",
    "\n",
    "        target_mask_mass = tf.reduce_sum(target_mask)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_sequence)\n",
    "            prediction = tf.reduce_sum(\n",
    "              target_mask[tf.newaxis] *\n",
    "              self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n",
    "\n",
    "        input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n",
    "        input_grad = tf.squeeze(input_grad, axis=0)\n",
    "        return tf.reduce_sum(input_grad, axis=-1)\n",
    "    \n",
    "    def __call__(self, inputs: tf.Tensor,\n",
    "                   is_training: bool) -> Dict[str, tf.Tensor]:\n",
    "        trunk_embedding = self.trunk(inputs, is_training=is_training)\n",
    "        return {\n",
    "            head: head_module(trunk_embedding, is_training=is_training)\n",
    "            for head, head_module in self.heads.items()\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsRaw:\n",
    "\n",
    "      def __init__(self, tfhub_url, organism='human'):\n",
    "        self._model = Enformer(tfhub_url)\n",
    "        self._organism = organism\n",
    "  \n",
    "      def predict_on_batch(self, inputs):\n",
    "        ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n",
    "        alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n",
    "\n",
    "        return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsNormalized:\n",
    "\n",
    "    def __init__(self, tfhub_url, transform_pkl_path,\n",
    "                   organism='human'):\n",
    "        assert organism == 'human', 'Transforms only compatible with organism=human'\n",
    "        self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "        with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "          transform_pipeline = joblib.load(f)\n",
    "        self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n",
    "\n",
    "    def predict_on_batch(self, inputs):\n",
    "        scores = self._model.predict_on_batch(inputs)\n",
    "        return self._transform.transform(scores)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsPCANormalized:\n",
    "\n",
    "    def __init__(self, tfhub_url, transform_pkl_path,\n",
    "                   organism='human', num_top_features=500):\n",
    "        self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "        with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "          self._transform = joblib.load(f)\n",
    "        self._num_top_features = num_top_features\n",
    "\n",
    "    def predict_on_batch(self, inputs):\n",
    "        scores = self._model.predict_on_batch(inputs)\n",
    "        return self._transform.transform(scores)[:, :self._num_top_features]\n",
    "    \n",
    "class FastaStringExtractor:\n",
    "    \n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91386fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Enformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3e380ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_extractor = FastaStringExtractor(fasta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2f5d7",
   "metadata": {},
   "source": [
    "### Check tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee0b5360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genome</th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>clip</th>\n",
       "      <th>scale</th>\n",
       "      <th>sum_stat</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF833POA</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:cerebellum male adult (27 years) and mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF110QGM</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:frontal cortex male adult (27 years) and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF880MKD</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:chorion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF463ZLQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:Ishikawa treated with 0.02% dimethyl sul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ENCFF890OGQ</td>\n",
       "      <td>/home/drk/tillage/datasets/human/dnase/encode/...</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>mean</td>\n",
       "      <td>DNASE:GM03348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>5308</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14239</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:epithelioid sarcoma cell line:HS-ES-2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>5309</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14240</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:squamous cell lung carcinoma cell line:RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>5310</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14241</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:gastric cancer cell line:GSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>5311</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14244</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:carcinoid cell line:NCI-H727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>5312</td>\n",
       "      <td>0</td>\n",
       "      <td>CNhs14245</td>\n",
       "      <td>/home/drk/tillage/datasets/human/cage/fantom/C...</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>sum</td>\n",
       "      <td>CAGE:lung adenocarcinoma, papillary cell line:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5313 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  genome   identifier  \\\n",
       "0         0       0  ENCFF833POA   \n",
       "1         1       0  ENCFF110QGM   \n",
       "2         2       0  ENCFF880MKD   \n",
       "3         3       0  ENCFF463ZLQ   \n",
       "4         4       0  ENCFF890OGQ   \n",
       "...     ...     ...          ...   \n",
       "5308   5308       0    CNhs14239   \n",
       "5309   5309       0    CNhs14240   \n",
       "5310   5310       0    CNhs14241   \n",
       "5311   5311       0    CNhs14244   \n",
       "5312   5312       0    CNhs14245   \n",
       "\n",
       "                                                   file  clip  scale sum_stat  \\\n",
       "0     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "1     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "2     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "3     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "4     /home/drk/tillage/datasets/human/dnase/encode/...    32      2     mean   \n",
       "...                                                 ...   ...    ...      ...   \n",
       "5308  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5309  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5310  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5311  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "5312  /home/drk/tillage/datasets/human/cage/fantom/C...   384      1      sum   \n",
       "\n",
       "                                            description  \n",
       "0     DNASE:cerebellum male adult (27 years) and mal...  \n",
       "1     DNASE:frontal cortex male adult (27 years) and...  \n",
       "2                                         DNASE:chorion  \n",
       "3     DNASE:Ishikawa treated with 0.02% dimethyl sul...  \n",
       "4                                         DNASE:GM03348  \n",
       "...                                                 ...  \n",
       "5308        CAGE:epithelioid sarcoma cell line:HS-ES-2R  \n",
       "5309  CAGE:squamous cell lung carcinoma cell line:RE...  \n",
       "5310                  CAGE:gastric cancer cell line:GSS  \n",
       "5311                  CAGE:carcinoid cell line:NCI-H727  \n",
       "5312  CAGE:lung adenocarcinoma, papillary cell line:...  \n",
       "\n",
       "[5313 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download targets from Basenji2 dataset \n",
    "# Cite: Kelley et al Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\n",
    "targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
    "df_targets = pd.read_csv(targets_txt, sep='\\t')\n",
    "df_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c07dcd",
   "metadata": {},
   "source": [
    "## predict human validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cc5e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_interval = kipoiseq.Interval('chr1', 35_082_742, 35_197_430)  \n",
    "\n",
    "# One hot encode \n",
    "# resize only takes the sequence of that interval, center it and gets the reduced sequence length \n",
    "sequence_one_hot = one_hot_encode(fasta_extractor.extract(target_interval.resize(393216)))\n",
    "\n",
    "# Predict on that sequence\n",
    "predictions = model.predict_on_batch(sequence_one_hot[np.newaxis])['human'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a57eab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.50549219e-03, 1.58413667e-02, 5.63042536e-02, 3.39204110e-02,\n",
       "       4.74021807e-02, 8.28567967e-02, 6.69879243e-02, 2.55072415e-02,\n",
       "       2.35070698e-02, 8.42880532e-02, 1.09183863e-01, 1.03348963e-01,\n",
       "       1.13832407e-01, 1.35337815e-01, 1.30810678e-01, 1.26478016e-01,\n",
       "       1.30831897e-01, 1.08674467e-01, 1.68840867e-02, 1.57137564e-03,\n",
       "       6.97181970e-02, 1.64800078e-01, 1.79596424e-01, 1.39135689e-01,\n",
       "       1.06212147e-01, 1.00273758e-01, 7.68458992e-02, 5.08518554e-02,\n",
       "       2.55599953e-02, 8.27139467e-02, 7.20480606e-02, 2.39708293e-02,\n",
       "       8.59023130e-04, 9.85492952e-03, 6.36985246e-03, 3.91527824e-02,\n",
       "       5.10640815e-02, 1.69637613e-03, 1.57112014e-02, 3.00747268e-02,\n",
       "       1.82608829e-03, 2.42718067e-02, 1.20249167e-02, 2.82154116e-03,\n",
       "       3.24195391e-03, 6.53163269e-02, 1.17052682e-01, 4.80120666e-02,\n",
       "       5.21726627e-03, 3.82351503e-02, 9.86452103e-02, 1.02631025e-01,\n",
       "       1.13904156e-01, 6.09156340e-02, 5.77645972e-02, 7.97166303e-03,\n",
       "       2.58073909e-03, 3.88052734e-03, 7.64453933e-02, 9.26418751e-02,\n",
       "       4.41224687e-02, 7.89127424e-02, 9.34633147e-03, 6.35067653e-03,\n",
       "       6.80501312e-02, 8.90799612e-02, 1.08002881e-02, 1.57305971e-03,\n",
       "       5.77413030e-02, 6.26156181e-02, 1.57671254e-02, 2.48493999e-02,\n",
       "       2.66959914e-03, 4.09895275e-03, 9.05954838e-03, 5.58908423e-03,\n",
       "       4.62367013e-03, 3.81929101e-03, 6.69151917e-03, 4.54628356e-02,\n",
       "       8.98939818e-02, 1.18726715e-01, 6.11197092e-02, 9.19924676e-03,\n",
       "       2.58270372e-02, 1.03315465e-01, 1.01324089e-01, 9.20164883e-02,\n",
       "       1.00341849e-01, 8.85076299e-02, 8.77749324e-02, 4.02776785e-02,\n",
       "       3.88208553e-02, 1.50305759e-02, 3.28610539e-02, 7.69685954e-02,\n",
       "       9.62418467e-02, 3.79172862e-02, 1.40749114e-02, 2.89484840e-02,\n",
       "       9.77568030e-02, 6.50200546e-02, 5.17413020e-02, 6.32718652e-02,\n",
       "       5.98213123e-03, 2.67637474e-03, 1.55325364e-02, 1.29724005e-02,\n",
       "       1.02781625e-02, 1.50272110e-02, 5.71380882e-03, 6.21522963e-03,\n",
       "       4.38296385e-02, 8.33694041e-02, 1.42142773e-01, 1.30859837e-01,\n",
       "       3.15434784e-02, 3.39343771e-03, 2.46591978e-02, 6.65449947e-02,\n",
       "       7.77660534e-02, 7.88446963e-02, 9.04592052e-02, 8.24209005e-02,\n",
       "       1.89954881e-02, 1.64782181e-02, 8.01289305e-02, 7.94611350e-02,\n",
       "       9.48260203e-02, 1.02242552e-01, 9.87996012e-02, 7.06399381e-02,\n",
       "       5.90720810e-02, 2.65625436e-02, 1.29778227e-02, 5.17608039e-03,\n",
       "       3.73809412e-02, 3.96510549e-02, 1.13982204e-02, 2.29731090e-02,\n",
       "       7.12180734e-02, 2.70781629e-02, 1.82327237e-02, 1.37280961e-02,\n",
       "       7.97376875e-03, 3.52578498e-02, 8.34381580e-02, 8.51477608e-02,\n",
       "       3.60131450e-02, 5.40512502e-02, 6.11750968e-02, 9.09208879e-02,\n",
       "       9.90259647e-02, 7.85560682e-02, 6.22341447e-02, 7.94357136e-02,\n",
       "       9.62465331e-02, 7.61011466e-02, 8.36805776e-02, 8.36116001e-02,\n",
       "       6.54286146e-02, 4.84143160e-02, 6.13102019e-02, 6.90457672e-02,\n",
       "       9.60730240e-02, 8.57403576e-02, 3.95736434e-02, 7.66831264e-02,\n",
       "       9.00977179e-02, 9.79456231e-02, 9.58946198e-02, 1.17046483e-01,\n",
       "       1.04763977e-01, 9.00590122e-02, 4.11532521e-02, 3.09630530e-03,\n",
       "       1.76268874e-03, 4.70228773e-03, 1.30803222e-02, 1.17563196e-02,\n",
       "       3.95830907e-02, 5.30486032e-02, 6.55545443e-02, 1.08296379e-01,\n",
       "       3.27967294e-02, 1.63579907e-03, 4.56302762e-02, 7.63948411e-02,\n",
       "       7.59760151e-03, 7.65914517e-03, 1.39532303e-02, 6.58157421e-03,\n",
       "       2.75573181e-03, 9.01371911e-02, 1.05299637e-01, 6.18995242e-02,\n",
       "       1.32677369e-02, 1.38062285e-02, 4.05210555e-02, 6.31185398e-02,\n",
       "       1.24441786e-02, 8.34153872e-03, 4.59149443e-02, 4.78842594e-02,\n",
       "       1.53994877e-02, 1.51421046e-02, 1.66179873e-02, 4.32413928e-02,\n",
       "       8.84873420e-02, 9.83404815e-02, 9.15877521e-02, 1.53082348e-02,\n",
       "       6.02207938e-03, 3.21618803e-02, 6.13772720e-02, 8.39891136e-02,\n",
       "       5.37603572e-02, 5.15400991e-02, 1.12966783e-02, 1.49165594e-03,\n",
       "       3.60747874e-02, 8.02938938e-02, 1.11309141e-01, 1.32702246e-01,\n",
       "       8.46091956e-02, 8.33440349e-02, 8.60784352e-02, 9.09862667e-02,\n",
       "       6.40306175e-02, 6.12731241e-02, 8.91284365e-03, 2.28233449e-03,\n",
       "       3.10586067e-03, 8.51948559e-03, 1.26332134e-01, 1.59043774e-01,\n",
       "       1.01542786e-01, 1.13329291e-01, 1.47258073e-01, 1.31173819e-01,\n",
       "       9.62713435e-02, 8.85983407e-02, 9.68457535e-02, 9.48223174e-02,\n",
       "       7.85550997e-02, 8.78767893e-02, 1.04532845e-01, 9.35119390e-02,\n",
       "       8.77700746e-02, 7.31749460e-02, 7.66955614e-02, 1.09862223e-01,\n",
       "       1.18390009e-01, 1.11828215e-01, 1.08553022e-01, 1.14671566e-01,\n",
       "       1.10170163e-01, 1.13663219e-01, 1.17819116e-01, 9.22860652e-02,\n",
       "       4.53161076e-02, 5.55846728e-02, 1.10139161e-01, 4.18381318e-02,\n",
       "       2.25400762e-03, 3.56282480e-02, 3.41883376e-02, 3.38907936e-04,\n",
       "       3.30935530e-02, 8.88730660e-02, 2.98783761e-02, 2.70334003e-03,\n",
       "       1.77207906e-02, 8.73727072e-03, 2.18659341e-02, 1.35591794e-02,\n",
       "       5.96303435e-04, 5.87593615e-02, 9.52946842e-02, 1.09227281e-02,\n",
       "       1.29540982e-02, 9.02585164e-02, 1.28876150e-01, 1.31902114e-01,\n",
       "       2.39937659e-02, 6.61378680e-03, 8.94666016e-02, 1.73207179e-01,\n",
       "       1.45370007e-01, 3.12196705e-02, 2.19585933e-02, 1.59544900e-01,\n",
       "       1.91438049e-01, 1.83307454e-01, 1.41436979e-01, 6.16429895e-02,\n",
       "       1.00858368e-01, 3.16146225e-01, 3.86022151e-01, 3.91712636e-01,\n",
       "       2.47268468e-01, 2.58019436e-02, 1.59473252e-03, 6.93125203e-02,\n",
       "       1.86799780e-01, 1.69201121e-01, 1.51909947e-01, 1.55926630e-01,\n",
       "       1.54148266e-01, 1.27507716e-01, 2.13007152e-01, 2.55383044e-01,\n",
       "       1.95247263e-01, 1.63745478e-01, 1.52378663e-01, 4.49891165e-02,\n",
       "       1.11571671e-02, 2.99403761e-02, 7.57299140e-02, 8.73968527e-02,\n",
       "       9.05888621e-03, 5.54073369e-03, 2.00512633e-02, 3.73456515e-02,\n",
       "       5.40020950e-02, 5.74879274e-02, 1.85368620e-02, 1.58820450e-02,\n",
       "       2.29953863e-02, 1.04011614e-02, 3.77842933e-02, 9.21209715e-03,\n",
       "       1.07233319e-03, 2.22273469e-02, 9.61464942e-02, 8.31268206e-02,\n",
       "       1.84360482e-02, 2.80597247e-03, 9.02491063e-03, 2.66792774e-02,\n",
       "       6.10018708e-02, 2.72484180e-02, 1.28483688e-02, 8.90962705e-02,\n",
       "       8.68979022e-02, 2.27039810e-02, 2.34647421e-03, 3.06610782e-02,\n",
       "       5.18391170e-02, 2.96337679e-02, 3.90865607e-03, 1.67109426e-02,\n",
       "       3.51968817e-02, 2.85847373e-02, 2.62764245e-02, 3.26011628e-02,\n",
       "       2.38363948e-02, 8.03591497e-03, 1.92075490e-03, 1.03283096e-02,\n",
       "       2.23171059e-02, 1.93619635e-02, 3.25484015e-02, 4.09609079e-02,\n",
       "       4.09683734e-02, 4.05847877e-02, 4.46039401e-02, 4.99348715e-02,\n",
       "       5.37976809e-02, 5.28716184e-02, 2.19635647e-02, 3.46075855e-02,\n",
       "       1.99392810e-02, 4.45197076e-02, 8.20103288e-02, 6.47955984e-02,\n",
       "       4.51338738e-02, 1.64664388e-02, 6.72379835e-03, 4.76948172e-03,\n",
       "       1.21023199e-02, 1.89394429e-02, 2.59877313e-02, 2.87008937e-02,\n",
       "       2.27480736e-02, 1.30178472e-02, 5.26025472e-03, 4.80598956e-03,\n",
       "       4.72662970e-03, 4.60399454e-03, 3.40513699e-03, 4.26577404e-03,\n",
       "       7.77306734e-03, 6.25051092e-03, 6.56690449e-03, 1.13184731e-02,\n",
       "       1.04006184e-02, 8.06997623e-03, 6.81283232e-03, 5.65328822e-03,\n",
       "       5.36133116e-03, 4.53208527e-03, 7.50457449e-03, 6.27681287e-03,\n",
       "       2.96818349e-03, 3.54968337e-03, 1.00225881e-02, 9.13668796e-03,\n",
       "       5.25946915e-03, 5.81967598e-03, 5.20081446e-03, 3.95333255e-03,\n",
       "       1.21103069e-02, 6.02297252e-03, 4.18822514e-03, 5.60122123e-03,\n",
       "       9.04350542e-03, 1.29596600e-02, 8.89307726e-03, 5.95673406e-03,\n",
       "       8.17980058e-03, 6.05914136e-03, 1.60577260e-02, 1.62602384e-02,\n",
       "       2.75643095e-02, 2.52632648e-02, 1.58160143e-02, 9.25119501e-03,\n",
       "       9.12825670e-03, 4.74467454e-03, 5.98700764e-03, 1.88500918e-02,\n",
       "       2.17939727e-02, 2.00399216e-02, 2.24699471e-02, 2.07670443e-02,\n",
       "       1.86014939e-02, 1.83854550e-02, 1.48681263e-02, 1.86689813e-02,\n",
       "       2.06566788e-02, 2.42209360e-02, 1.87127534e-02, 1.89727936e-02,\n",
       "       1.77676883e-02, 1.94571260e-02, 1.75413713e-02, 1.07599571e-02,\n",
       "       1.07671702e-02, 1.13350023e-02, 9.38281137e-03, 1.74267758e-02,\n",
       "       2.04080250e-02, 1.61389448e-02, 4.38585551e-03, 4.80340235e-03,\n",
       "       2.57023722e-02, 2.54906658e-02, 2.51186695e-02, 3.05764377e-02,\n",
       "       3.23707983e-02, 3.86582389e-02, 5.28377034e-02, 5.37913553e-02,\n",
       "       5.76518811e-02, 5.88038191e-02, 6.06191233e-02, 5.69638349e-02,\n",
       "       4.69944589e-02, 2.81244814e-02, 2.70629395e-02, 2.59010904e-02,\n",
       "       2.74189301e-02, 3.56281586e-02, 3.96254323e-02, 5.02256714e-02,\n",
       "       6.20330498e-02, 5.45740873e-02, 6.12514727e-02, 7.54957944e-02,\n",
       "       6.69888854e-02, 5.42365015e-02, 2.88206413e-02, 2.43717246e-02,\n",
       "       2.33661998e-02, 3.38530168e-02, 3.23109366e-02, 3.35878953e-02,\n",
       "       3.69368158e-02, 4.41439785e-02, 4.57523279e-02, 4.36294265e-02,\n",
       "       4.38286550e-02, 3.21256183e-02, 2.42400654e-02, 1.92076191e-02,\n",
       "       3.84521969e-02, 6.60961047e-02, 4.82175052e-02, 2.16448605e-02,\n",
       "       2.80405805e-02, 2.51792762e-02, 2.13373639e-02, 1.35345664e-02,\n",
       "       1.48145780e-02, 2.36871485e-02, 1.57444179e-02, 1.45796663e-03,\n",
       "       1.09731937e-02, 2.37607993e-02, 2.05454510e-02, 1.24741420e-02,\n",
       "       2.01375410e-02, 2.13345028e-02, 1.77489296e-02, 2.84236632e-02,\n",
       "       1.82537548e-02, 2.49896888e-02, 4.97627296e-02, 5.68125062e-02,\n",
       "       2.48346459e-02, 5.74106874e-04, 2.75971778e-02, 3.79103087e-02,\n",
       "       1.06096091e-02, 5.78696793e-03, 1.20951561e-02, 1.59666277e-02,\n",
       "       2.90547851e-02, 2.74655269e-03, 1.26067025e-03, 1.09160843e-03,\n",
       "       1.13324979e-02, 2.70831827e-02, 3.75502673e-03, 2.08543893e-02,\n",
       "       4.93276678e-02, 7.26076216e-02, 3.94212827e-02, 9.75377299e-03,\n",
       "       2.11356319e-02, 9.50836167e-02, 1.15845278e-01, 1.14137948e-01,\n",
       "       5.84875792e-02, 1.38057321e-02, 3.89411263e-02, 1.22960418e-01,\n",
       "       1.02852426e-01, 3.13692428e-02, 5.10357600e-03, 4.65946235e-02,\n",
       "       1.02744594e-01, 9.20512900e-02, 1.09146632e-01, 6.49714544e-02,\n",
       "       1.92115195e-02, 2.22054310e-02, 5.81388175e-03, 8.12040083e-03,\n",
       "       6.18111063e-03, 1.65734477e-02, 3.44793312e-02, 1.04677029e-01,\n",
       "       1.05587646e-01, 1.25046581e-01, 1.47795796e-01, 1.34984881e-01,\n",
       "       1.26947492e-01, 2.51490977e-02, 3.82341072e-03, 4.04799990e-02,\n",
       "       9.54758003e-02, 8.69577453e-02, 2.65653487e-02, 7.99653004e-04,\n",
       "       3.34721543e-02, 6.04305416e-02, 2.55734082e-02, 1.09946337e-02,\n",
       "       3.92558835e-02, 6.34951591e-02, 8.02352093e-03, 1.25608025e-02,\n",
       "       4.78506908e-02, 7.56036043e-02, 9.18001756e-02, 6.87558725e-02,\n",
       "       2.80273035e-02, 6.96482509e-02, 5.51260822e-02, 1.92687847e-02,\n",
       "       3.80213279e-03, 2.49431171e-02, 2.57609971e-02, 8.24608933e-03,\n",
       "       1.97464097e-02, 5.88937895e-03, 5.79763157e-03, 3.01944334e-02,\n",
       "       2.37190407e-02, 4.73842360e-02, 1.82035717e-03, 4.22209129e-03,\n",
       "       9.83475000e-02, 1.70622289e-01, 1.34700805e-01, 1.16239071e-01,\n",
       "       2.13134848e-02, 7.75545416e-03, 6.19616918e-02, 9.06385258e-02,\n",
       "       8.88322145e-02, 1.06384970e-01, 3.59049179e-02, 5.32298407e-04,\n",
       "       5.98548539e-03, 5.91437751e-03, 3.74662573e-03, 6.35128021e-02,\n",
       "       9.69097838e-02, 1.04809374e-01, 1.93778023e-01, 1.07636109e-01,\n",
       "       1.20985284e-02, 1.69994906e-02, 8.17020014e-02, 1.02799401e-01,\n",
       "       9.33055356e-02, 6.48884773e-02, 7.33549614e-03, 2.89378059e-03,\n",
       "       1.77959576e-02, 1.32395867e-02, 1.32890884e-03, 2.21193042e-02,\n",
       "       6.35374114e-02, 2.32455749e-02, 3.34704630e-02, 2.44201012e-02,\n",
       "       1.69485211e-02, 5.44117950e-03, 4.67240922e-02, 3.41466181e-02,\n",
       "       1.39313256e-02, 2.53443606e-03, 2.14489084e-02, 3.80855538e-02,\n",
       "       2.16957200e-02, 4.44917427e-03, 5.25616808e-03, 5.67794545e-03,\n",
       "       2.51969579e-03, 8.00560601e-03, 9.88157233e-04, 7.34369387e-04,\n",
       "       2.97765154e-03, 9.88391321e-03, 3.70906107e-02, 6.29792735e-02,\n",
       "       1.92098413e-02, 7.94470217e-03, 4.04303037e-02, 7.19876811e-02,\n",
       "       7.68398345e-02, 8.10891613e-02, 3.68122458e-02, 8.79507884e-03,\n",
       "       3.92229594e-02, 8.62460509e-02, 6.54001534e-02, 4.81287129e-02,\n",
       "       6.62610233e-02, 4.63731550e-02, 7.55440816e-02, 4.54172008e-02,\n",
       "       1.12046220e-03, 3.93234892e-03, 6.94163376e-03, 1.27005475e-02,\n",
       "       6.47909492e-02, 1.02846913e-01, 1.34263396e-01, 1.36538953e-01,\n",
       "       1.27988651e-01, 1.32074833e-01, 1.05197221e-01, 6.00307286e-02,\n",
       "       5.59360161e-03, 1.57925040e-02, 4.91824523e-02, 9.20510758e-03,\n",
       "       5.07912319e-03, 7.00367317e-02, 9.36480239e-02, 5.34662791e-02,\n",
       "       2.90012881e-02, 4.16365042e-02, 8.05100277e-02, 6.50421679e-02,\n",
       "       3.07445345e-03, 3.89556289e-02, 6.83604032e-02, 9.88406688e-03,\n",
       "       1.49639202e-02, 8.80051591e-03, 2.57489793e-02, 5.70428967e-02,\n",
       "       8.53653476e-02, 1.22174479e-01, 1.06894135e-01, 1.20748408e-01,\n",
       "       1.31709278e-01, 1.57537580e-01, 1.53459907e-01, 1.35064393e-01,\n",
       "       1.23836316e-01, 1.15818597e-01, 6.13023378e-02, 1.69593189e-02,\n",
       "       3.70747633e-02, 9.81776938e-02, 1.01675801e-01, 3.22024301e-02,\n",
       "       8.66620541e-02, 9.53606889e-02, 1.24020681e-01, 1.21220127e-01,\n",
       "       1.01615198e-01, 8.92872587e-02, 1.08934648e-01, 1.06048062e-01,\n",
       "       1.15239918e-01, 2.51969900e-02, 1.01697091e-02, 2.92388424e-02,\n",
       "       1.02047343e-02, 1.27902562e-02, 9.09244865e-02, 8.35636482e-02,\n",
       "       2.64206026e-02, 6.87814504e-02, 1.06088161e-01, 1.01356439e-01,\n",
       "       9.63488594e-02, 8.95029753e-02, 1.24006607e-01, 1.58508763e-01,\n",
       "       1.52177975e-01, 1.37983382e-01, 1.32299840e-01, 8.38409960e-02,\n",
       "       1.50974691e-01, 1.58243790e-01, 1.33324385e-01, 1.21028192e-01,\n",
       "       1.02800176e-01, 1.13395169e-01, 1.24516040e-01, 1.38707146e-01,\n",
       "       1.40784606e-01, 1.39845565e-01, 1.36425644e-01, 1.47899657e-01,\n",
       "       1.18021332e-01, 1.35568351e-01, 1.83286771e-01, 1.88861802e-01,\n",
       "       1.59017920e-01, 1.44388869e-01, 9.99126062e-02, 9.97745991e-02,\n",
       "       9.15649533e-02, 9.23851728e-02, 1.06135197e-01, 1.17004491e-01,\n",
       "       1.04716256e-01, 1.18083544e-01, 1.31240293e-01, 1.43650711e-01,\n",
       "       1.26646057e-01, 1.36725664e-01, 1.43138394e-01, 1.32901475e-01,\n",
       "       9.86659974e-02, 1.26781156e-02, 2.13258411e-03, 5.02697900e-02,\n",
       "       1.03323728e-01, 1.16116233e-01, 1.13750815e-01, 1.22466989e-01,\n",
       "       9.29967165e-02, 1.10098831e-01, 1.09603442e-01, 1.10020317e-01,\n",
       "       1.01899691e-01, 1.12220459e-01, 1.22934237e-01, 1.44204438e-01,\n",
       "       1.20733604e-01, 1.29435375e-01, 1.20208450e-01, 1.11172743e-01,\n",
       "       1.00950889e-01, 1.05776183e-01, 1.07784182e-01, 1.05927408e-01,\n",
       "       1.37083858e-01, 1.38089478e-01, 1.35156661e-01, 1.32657453e-01,\n",
       "       1.18963018e-01, 8.80423859e-02, 1.48762465e-01, 1.46348581e-01,\n",
       "       1.08663902e-01, 8.65646675e-02, 1.98665503e-02, 7.45070772e-03,\n",
       "       3.90089899e-02, 1.18214361e-01, 1.47658587e-01, 1.44736081e-01,\n",
       "       1.23380877e-01, 7.48320818e-02, 3.66800204e-02, 2.81359479e-02,\n",
       "       1.32306721e-02, 3.59565280e-02, 1.28057599e-01, 8.75442475e-02,\n",
       "       9.49466377e-02, 1.46502957e-01, 1.48437202e-01, 6.22413084e-02,\n",
       "       8.23906995e-03, 2.74224263e-02, 1.29893795e-02, 4.23461124e-02,\n",
       "       1.52436137e-01, 9.55144241e-02, 1.56423688e-01, 1.70402691e-01,\n",
       "       1.89357802e-01, 2.47175157e-01, 2.27694139e-01, 1.56952605e-01,\n",
       "       1.59672543e-01, 2.24020094e-01, 2.43374228e-01, 3.42026323e-01,\n",
       "       8.41177225e-01, 2.72374415e+00, 5.80971909e+00, 1.93067551e+00,\n",
       "       9.94964361e-01, 7.92947948e-01, 9.22041655e-01, 1.62430227e-01,\n",
       "       3.25236440e-01, 3.76843274e-01, 7.91345882e+00, 1.02443075e+01,\n",
       "       4.91627693e+00, 1.02561522e+00, 4.60664928e-01, 2.45306179e-01,\n",
       "       4.04674858e-02, 1.78564675e-02, 2.85874400e-03, 2.09461208e-02,\n",
       "       4.12391610e-02, 4.75234129e-02, 9.80225857e-03, 5.13127334e-02,\n",
       "       1.03230417e-01, 2.24576741e-02, 1.94005538e-02, 1.69607297e-01,\n",
       "       1.64327309e-01, 1.96777973e-02, 7.72562064e-03, 9.44581628e-02,\n",
       "       1.20509095e-01, 1.26269132e-01, 9.63401049e-02, 1.83867607e-02,\n",
       "       7.67612457e-03, 9.90321115e-03, 1.39002623e-02, 1.29104525e-01,\n",
       "       1.53110251e-01, 1.30897701e-01, 2.17288826e-02, 7.16977660e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ba8d4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 5313)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "92723a53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'human_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3832746/3301413446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# keep only validation intervals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_intervals\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_intervals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_intervals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'human_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(human_sequences, memory_map=True, header=None, index_col=False, delimiter=\"\\t\")\n",
    "\n",
    "# keep only validation intervals \n",
    "validation_intervals= df[df[3]==\"valid\"]\n",
    "validation_intervals = validation_intervals.head()\n",
    "\n",
    "\n",
    "# create list with interval\n",
    "interval_list = list()\n",
    "validation_intervals.apply(lambda row : interval_list.append(kipoiseq.Interval(row[0],row[1], row[2])), axis = 1)\n",
    "interval_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0efa3516",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_intervals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3832746/2221266644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_intervals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_intervals' is not defined"
     ]
    }
   ],
   "source": [
    "validation_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fda2223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_interval = interval_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "966c827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize only takes the sequence of that interval, center it and gets the reduced sequence length \n",
    "sequence_one_hot = one_hot_encode(fasta_extractor.extract(my_interval.resize(SEQUENCE_LENGTH)))\n",
    "# Predict on that sequence\n",
    "predictions = model.predict_on_batch(sequence_one_hot[np.newaxis])['human'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "13d97e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 5313)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8246c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load utils\n",
    "# @title `get_dataset(organism, subset, num_threads=8)`\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import functools\n",
    "\n",
    "\n",
    "def organism_path(organism):\n",
    "    return os.path.join('gs://basenji_barnyard/data', organism)\n",
    "\n",
    "#\n",
    "def get_dataset(organism, subset, num_threads=8):\n",
    "    \n",
    "    metadata = get_metadata(organism)\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files(organism, subset),\n",
    "                                        compression_type='ZLIB',\n",
    "                                        num_parallel_reads=num_threads)\n",
    "    dataset = dataset.map(functools.partial(deserialize, metadata=metadata),\n",
    "                            num_parallel_calls=num_threads)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_metadata(organism):\n",
    "  # Keys:\n",
    "  # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n",
    "  # pool_width, crop_bp, target_length\n",
    "    path = os.path.join(organism_path(organism), 'statistics.json')\n",
    "    with tf.io.gfile.GFile(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def tfrecord_files(organism, subset):\n",
    "  # Sort the values by int(*).\n",
    "  return sorted(tf.io.gfile.glob(os.path.join(\n",
    "      organism_path(organism), 'tfrecords', f'{subset}-*.tfr'\n",
    "  )), key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "\n",
    "def deserialize(serialized_example, metadata):\n",
    "    \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "    feature_map = {\n",
    "          'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "          'target': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_example(serialized_example, feature_map)\n",
    "    sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "    sequence = tf.reshape(sequence, (metadata['seq_length'], 4))\n",
    "    sequence = tf.cast(sequence, tf.float32)\n",
    "\n",
    "    target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "    target = tf.reshape(target,\n",
    "                          (metadata['target_length'], metadata['num_targets']))\n",
    "    target = tf.cast(target, tf.float32)\n",
    "\n",
    "    return {'sequence': sequence,\n",
    "              'target': target}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917fd13",
   "metadata": {},
   "source": [
    "### compute score (how well predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4a615e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real values \n",
    "# Get the 896 long string\n",
    "\n",
    "human_dataset = get_dataset('human', 'valid').batch(1).repeat()\n",
    "\n",
    "\n",
    "# Get predicted values \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8f08c3e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3832746/1300299421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhuman_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3832746/1300299421.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhuman_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2838\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2839\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2840\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2841\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m         \"output_shapes\", output_shapes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_size = sum(1 for _ in human_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10baa15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduced_shape(shape, axis):\n",
    "    if axis is None:\n",
    "        return tf.TensorShape([])\n",
    "    return tf.TensorShape([d for i, d in enumerate(shape) if i not in axis])\n",
    "\n",
    "\n",
    "class CorrelationStats(tf.keras.metrics.Metric):\n",
    "    \"\"\"Contains shared code for PearsonR and R2.\"\"\"\n",
    "\n",
    "    def __init__(self, reduce_axis=None, name='pearsonr'):\n",
    "        \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "        Args:\n",
    "          reduce_axis: Specifies over which axis to compute the correlation (say\n",
    "            (0, 1). If not specified, it will compute the correlation across the\n",
    "            whole tensor.\n",
    "          name: Metric name.\n",
    "        \"\"\"\n",
    "        super(CorrelationStats, self).__init__(name=name)\n",
    "        self._reduce_axis = reduce_axis\n",
    "        self._shape = None  # Specified in _initialize.\n",
    "\n",
    "    def _initialize(self, input_shape):\n",
    "        # Remaining dimensions after reducing over self._reduce_axis.\n",
    "        self._shape = _reduced_shape(input_shape, self._reduce_axis)\n",
    "\n",
    "        weight_kwargs = dict(shape=self._shape, initializer='zeros')\n",
    "        self._count = self.add_weight(name='count', **weight_kwargs)\n",
    "        self._product_sum = self.add_weight(name='product_sum', **weight_kwargs)\n",
    "        self._true_sum = self.add_weight(name='true_sum', **weight_kwargs)\n",
    "        self._true_squared_sum = self.add_weight(name='true_squared_sum',\n",
    "                                                 **weight_kwargs)\n",
    "        self._pred_sum = self.add_weight(name='pred_sum', **weight_kwargs)\n",
    "        self._pred_squared_sum = self.add_weight(name='pred_squared_sum',\n",
    "                                                 **weight_kwargs)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"Update the metric state.\n",
    "\n",
    "        Args:\n",
    "          y_true: Multi-dimensional float tensor [batch, ...] containing the ground\n",
    "            truth values.\n",
    "          y_pred: float tensor with the same shape as y_true containing predicted\n",
    "            values.\n",
    "          sample_weight: 1D tensor aligned with y_true batch dimension specifying\n",
    "            the weight of individual observations.\n",
    "        \"\"\"\n",
    "        if self._shape is None:\n",
    "          # Explicit initialization check.\n",
    "          self._initialize(y_true.shape)\n",
    "        y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
    "        y_true = tf.cast(y_true, 'float32')\n",
    "        y_pred = tf.cast(y_pred, 'float32')\n",
    "\n",
    "        self._product_sum.assign_add(\n",
    "            tf.reduce_sum(y_true * y_pred, axis=self._reduce_axis))\n",
    "\n",
    "        self._true_sum.assign_add(\n",
    "            tf.reduce_sum(y_true, axis=self._reduce_axis))\n",
    "\n",
    "        self._true_squared_sum.assign_add(\n",
    "            tf.reduce_sum(tf.math.square(y_true), axis=self._reduce_axis))\n",
    "\n",
    "        self._pred_sum.assign_add(\n",
    "            tf.reduce_sum(y_pred, axis=self._reduce_axis))\n",
    "\n",
    "        self._pred_squared_sum.assign_add(\n",
    "            tf.reduce_sum(tf.math.square(y_pred), axis=self._reduce_axis))\n",
    "\n",
    "        self._count.assign_add(\n",
    "            tf.reduce_sum(tf.ones_like(y_true), axis=self._reduce_axis))\n",
    "\n",
    "    def result(self):\n",
    "        raise NotImplementedError('Must be implemented in subclasses.')\n",
    "\n",
    "    def reset_states(self):\n",
    "        if self._shape is not None:\n",
    "            tf.keras.backend.batch_set_value([(v, np.zeros(self._shape))\n",
    "                                        for v in self.variables])\n",
    "\n",
    "\n",
    "class PearsonR(CorrelationStats):\n",
    "    \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "          Computed as:\n",
    "      ((x - x_avg) * (y - y_avg) / sqrt(Var[x] * Var[y])\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self, reduce_axis=(0,), name='pearsonr'):\n",
    "        \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "        Args:\n",
    "          reduce_axis: Specifies over which axis to compute the correlation.\n",
    "          name: Metric name.\n",
    "        \"\"\"\n",
    "        super(PearsonR, self).__init__(reduce_axis=reduce_axis,\n",
    "                                       name=name)\n",
    "\n",
    "    def result(self):\n",
    "        true_mean = self._true_sum / self._count\n",
    "        pred_mean = self._pred_sum / self._count\n",
    "\n",
    "        covariance = (self._product_sum\n",
    "                      - true_mean * self._pred_sum\n",
    "                      - pred_mean * self._true_sum\n",
    "                      + self._count * true_mean * pred_mean)\n",
    "\n",
    "        true_var = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
    "        pred_var = self._pred_squared_sum - self._count * tf.math.square(pred_mean)\n",
    "        tp_var = tf.math.sqrt(true_var) * tf.math.sqrt(pred_var)\n",
    "        correlation = covariance / tp_var\n",
    "\n",
    "        return correlation\n",
    "\n",
    "\n",
    "class R2(CorrelationStats):\n",
    "    \"\"\"R-squared  (fraction of explained variance).\"\"\"\n",
    "\n",
    "    def __init__(self, reduce_axis=None, name='R2'):\n",
    "        \"\"\"R-squared metric.\n",
    "\n",
    "        Args:\n",
    "          reduce_axis: Specifies over which axis to compute the correlation.\n",
    "          name: Metric name.\n",
    "        \"\"\"\n",
    "        super(R2, self).__init__(reduce_axis=reduce_axis,\n",
    "                                 name=name)\n",
    "\n",
    "    def result(self):\n",
    "        true_mean = self._true_sum / self._count\n",
    "        total = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
    "        residuals = (self._pred_squared_sum - 2 * self._product_sum\n",
    "                     + self._true_squared_sum)\n",
    "\n",
    "        return tf.ones_like(residuals) - residuals / total\n",
    "\n",
    "\n",
    "class MetricDict:\n",
    "    def __init__(self, metrics):\n",
    "        self._metrics = metrics\n",
    "\n",
    "    def update_state(self, y_true, y_pred):\n",
    "        for k, metric in self._metrics.items():\n",
    "            metric.update_state(y_true, y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        return {k: metric.result() for k, metric in self._metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ff53f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, head, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    print(\"Metric dictionary created\")\n",
    "    \n",
    "    @tf.function\n",
    "    def predict(x):    \n",
    "        return model(x, is_training=False)[head]\n",
    "    \n",
    "    print(\"\")\n",
    "    for i, batch in tqdm(enumerate(dataset)):\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        #metric.update_state(batch['target'], predict(batch['sequence']))\n",
    "        metric.update_state(batch['target'], batch['target'])\n",
    "\n",
    "    return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences(model, dataset, head, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    print(\"Metric dictionary created\")\n",
    "    \n",
    "    @tf.function\n",
    "    def predict(x):    \n",
    "        return model(x, is_training=False)[head]\n",
    "    print(\" Predict funciton loaded\")\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(dataset)):\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        #metric.update_state(batch['target'], predict(batch['sequence']))\n",
    "        metric.update_state(batch['target'], batch['target'])\n",
    "\n",
    "    return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on first ten \n",
    "# Right now it evaluates the whole model and \n",
    "metrics_human = evaluate_model(model,\n",
    "                               dataset=get_dataset('human', 'valid').batch(2).prefetch(2),\n",
    "                               head='human',\n",
    "                               max_steps=10)\n",
    "print('')\n",
    "print({k: v.numpy().mean() for k, v in metrics_human.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb3f3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_dataset('human', 'valid').batch(1).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e63b9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dataset = get_dataset('human', 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "923fcddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = human_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a96010d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'sequence': <tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]]], dtype=float32)>, 'target': <tf.Tensor: shape=(1, 896, 5313), dtype=float32, numpy=\n",
      "array([[[0.09924316, 0.0927124 , 0.01834106, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.11126709, 0.1685791 , 0.03396606, ..., 0.        ,\n",
      "         0.984375  , 0.        ],\n",
      "        [0.14318848, 0.23217773, 0.01850891, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.00662994, 0.01672363, 0.00756454, ..., 0.01852417,\n",
      "         0.11566162, 0.        ],\n",
      "        [0.00411224, 0.00155735, 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.06958008, 0.03845215, 0.04312134, ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)>}\n",
      "1\n",
      "{'sequence': <tf.Tensor: shape=(1, 131072, 4), dtype=float32, numpy=\n",
      "array([[[0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.]]], dtype=float32)>, 'target': <tf.Tensor: shape=(1, 896, 5313), dtype=float32, numpy=\n",
      "array([[[0.12359619, 0.13122559, 0.04827881, ..., 0.08575439,\n",
      "         0.        , 0.23083496],\n",
      "        [0.1071167 , 0.11212158, 0.05841064, ..., 0.03527832,\n",
      "         0.09454346, 0.33129883],\n",
      "        [0.08789062, 0.0838623 , 0.01882935, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.12322998, 0.11651611, 0.065979  , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.14318848, 0.11682129, 0.14086914, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.14160156, 0.16235352, 0.21740723, ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in tqdm(enumerate(test_dataset)):\n",
    "    print(i)\n",
    "    print(batch)\n",
    "    batch_one = batch\n",
    "    if i > 0: \n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9f8cf77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_one[\"sequence\"].numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
