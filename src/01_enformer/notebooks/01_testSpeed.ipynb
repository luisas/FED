{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc46a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 16:15:04.688006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-09 16:15:04.688024: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-02-09 16:15:08.138585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-09 16:15:08.138602: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-09 16:15:08.138616: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (luisasantus-HP-EliteDesk-800-G5-TWR): /proc/driver/nvidia/version does not exist\n",
      "2022-02-09 16:15:08.138759: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "myDir = os.path.join(os.path.dirname(os.getcwd()), \"bin\")\n",
    "model_path = \"/home/luisasantus/Desktop/crg_cluster/data/FED/enformer/1\"\n",
    "sys.path.append(myDir)\n",
    "from utils_full import *\n",
    "model = Enformer(model_path)\n",
    "\n",
    "from enformer import *\n",
    "\n",
    "\n",
    "SEQUENCE_LENGHT = 393_216\n",
    "## pad the sequence with Ns (anyways ignored by the model)\n",
    "def pad_one_hot(sequence_one_hot, NEW_SIZE):\n",
    "    ADD_ENDS = int((NEW_SIZE - sequence_one_hot.shape[0])/2)\n",
    "    pad_zero = np.tile(np.array([0., 0., 0., 0.]), (ADD_ENDS, 1))\n",
    "    padded_left = np.append(pad_zero,sequence_one_hot, axis=0)\n",
    "    pad_sequence = np.append(padded_left,pad_zero, axis=0)\n",
    "    return(pad_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1cd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_197k_file = \"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/human/tfrecords_197k/valid-0-0_197k.pkl\"\n",
    "with open(dataset_197k_file, 'rb') as file:\n",
    "    dataset_197k = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89889680",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = dataset_197k[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  \"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/human/test_197.pkl\"\n",
    "with open(test, 'wb') as file:\n",
    "    pickle.dump(test_ds, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a00095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences_mod(model, dataset, head, dataset_197k_evaluation, max_steps=None):\n",
    "\n",
    "    # Given a tensor with a one-encoded sequence, predicts head tracks\n",
    "    def predict(x):\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "            \n",
    "        batch = dataset[i]\n",
    "        seq = batch['sequence']\n",
    "        t0 = time.time()\n",
    "        prediction = predict(seq)\n",
    "        t1 = time.time()\n",
    "        pred_time = t1-t0\n",
    "        print(\"predtime \"+ str(pred_time))\n",
    "        metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "        metric_seq.update_state(batch['target'][np.newaxis], prediction)\n",
    "        t2 = time.time()\n",
    "        metric_seq_time = t2-t1\n",
    "        print(\"metric time  \"+ str(metric_seq_time))\n",
    "        \n",
    "        pearson_seq = metric_seq.result()[\"PearsonR\"].numpy()\n",
    "        batch_validation = {\"sequence\": batch[\"sequence\"],\n",
    "                            \"target\": batch[\"target\"],\n",
    "                            \"interval\": batch[\"interval\"],\n",
    "                            \"PearsonR\": pearson_seq}\n",
    "        dataset_197k_evaluation.append(batch_validation)\n",
    "        \n",
    "        \n",
    "        t3 = time.time()\n",
    "        object_time = t3-t2\n",
    "        print(\"object time  \"+ str(object_time))\n",
    "\n",
    "\n",
    "    return dataset_197k_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_197k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_all_sequences_mod(model,\n",
    "                               dataset=test_ds,\n",
    "                               head=\"human\",\n",
    "                               dataset_197k_evaluation = [], \n",
    "                               max_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62971f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_ds):\n",
    "    return evaluate_model_all_sequences_mod(model,\n",
    "                               dataset=test_ds,\n",
    "                               head=\"human\",\n",
    "                               dataset_197k_evaluation = [], \n",
    "                               max_steps=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6595c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea86f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820cf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_seq(model, batch, head, max_steps=None):\n",
    "     \n",
    "    prediction = predict(batch['sequence'])\n",
    "    metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    metric_seq.update_state(batch['target'][np.newaxis], prediction)        \n",
    "    pearson_seq = metric_seq.result()[\"PearsonR\"].numpy()\n",
    "    batch_validation = {\"sequence\": batch[\"sequence\"],\n",
    "                            \"target\": batch[\"target\"],\n",
    "                            \"interval\": batch[\"interval\"],\n",
    "                            \"PearsonR\": pearson_seq}\n",
    "\n",
    "    return batch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list([test_ds, test_ds, test_ds, test_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be56455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrt(inp):\n",
    "    return(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_seq(model, batch, head, max_steps=None):\n",
    "    \n",
    "    prediction = predict(batch['sequence'])\n",
    "    metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    metric_seq.update_state(batch['target'][np.newaxis], prediction)        \n",
    "    pearson_seq = metric_seq.result()[\"PearsonR\"].numpy()\n",
    "    batch_validation = {\"sequence\": batch[\"sequence\"],\n",
    "                            \"target\": batch[\"target\"],\n",
    "                            \"interval\": batch[\"interval\"],\n",
    "                            \"PearsonR\": pearson_seq}\n",
    "\n",
    "    return batch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2672f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_seqxx(batch):\n",
    "    SEQUENCE_LENGHT = 393216\n",
    "    \n",
    "    def predict(x):\n",
    "        return x\n",
    "    \n",
    "    prediction = predict(batch['sequence'])\n",
    "    \n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6113f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "global model \n",
    "\n",
    "def evaluate_model_4(batch):\n",
    "    global head \n",
    "    prediction = batch['sequence']\n",
    "    \n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "args = [example ]\n",
    "results = [pool.apply(evaluate_model_4, args=args) for example in a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(\"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/human/data_human_tfrecords_valid-0-0.tfr\", compression_type='ZLIB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa940956",
   "metadata": {},
   "outputs": [],
   "source": [
    "shards = 2\n",
    "\n",
    "for i in range(shards):\n",
    "    writer = tf.data.experimental.TFRecordWriter(f\"output_file-part-{i}.tfrecord\")\n",
    "    writer.write(raw_dataset.shard(shards, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7499f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tfrecord(tfrecord_path, split_size):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        ds = tf.data.TFRecordDataset(tfrecord_path).batch(split_size)\n",
    "        batch = ds.make_one_shot_iterator().get_next()\n",
    "        part_num = 0\n",
    "        while True:\n",
    "            try:\n",
    "                records = sess.run(batch)\n",
    "                part_path = tfrecord_path + '.{:03d}'.format(part_num)\n",
    "                with tf.python_io.TFRecordWriter(part_path) as writer:\n",
    "                    for record in records:\n",
    "                        writer.write(record)\n",
    "                part_num += 1\n",
    "            except tf.errors.OutOfRangeError: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ITEMS_PER_FILE = 100 # Assuming we are saving 100 items per .tfrecord file\n",
    "\n",
    "\n",
    "batch_idx = 0\n",
    "for batch in raw_dataset.batch(ITEMS_PER_FILE):\n",
    "\n",
    "    # Converting `batch` back into a `Dataset`, assuming batch is a `tuple` of `tensors`\n",
    "    batch_ds = tf.data.Dataset.from_tensor_slices(tuple([*batch]))\n",
    "    filename = f'out.tfrecord.{batch_idx:03d}'\n",
    "\n",
    "    writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "    writer.write(batch_ds)\n",
    "\n",
    "    batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "results = [pool.apply(howmany_within_range, args=(row, 4, 8)) for row in data]\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()    \n",
    "\n",
    "print(results[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "list(chunks(range(10, 75), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75184e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list([1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f46af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_197k_file = \"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/human/tfrecords_197k/valid-0-0_197k.pkl\"\n",
    "with open(dataset_197k_file, 'rb') as file:\n",
    "    dataset_197k = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1a8e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_197k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
