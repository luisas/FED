{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6998af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "myDir = os.path.join(os.path.dirname(os.getcwd()), \"bin\")\n",
    "model_path = \"/home/luisasantus/Desktop/crg_cluster/data/FED/enformer/1\"\n",
    "sys.path.append(myDir)\n",
    "from utils_full import *\n",
    "model = Enformer(model_path)\n",
    "\n",
    "from enformer import *\n",
    "\n",
    "\n",
    "SEQUENCE_LENGHT = 393_216\n",
    "## pad the sequence with Ns (anyways ignored by the model)\n",
    "def pad_one_hot(sequence_one_hot, NEW_SIZE):\n",
    "    ADD_ENDS = int((NEW_SIZE - sequence_one_hot.shape[0])/2)\n",
    "    pad_zero = np.tile(np.array([0., 0., 0., 0.]), (ADD_ENDS, 1))\n",
    "    padded_left = np.append(pad_zero,sequence_one_hot, axis=0)\n",
    "    pad_sequence = np.append(padded_left,pad_zero, axis=0)\n",
    "    return(pad_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af0bb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02596e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_197k_file = \"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/human/tfrecords_197k/valid-0-0_197k.pkl\"\n",
    "with open(dataset_197k_file, 'rb') as file:\n",
    "    dataset_197k = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6c38198",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = dataset_197k[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90fafdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  \"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/human/test_197.pkl\"\n",
    "with open(test, 'wb') as file:\n",
    "    pickle.dump(test_ds, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ba85b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences_mod(model, dataset, head, dataset_197k_evaluation, max_steps=None):\n",
    "\n",
    "    # Given a tensor with a one-encoded sequence, predicts head tracks\n",
    "    def predict(x):\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "            \n",
    "        batch = dataset[i]\n",
    "        seq = batch['sequence']\n",
    "        t0 = time.time()\n",
    "        prediction = predict(seq)\n",
    "        t1 = time.time()\n",
    "        pred_time = t1-t0\n",
    "        print(\"predtime \"+ str(pred_time))\n",
    "        metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "        metric_seq.update_state(batch['target'][np.newaxis], prediction)\n",
    "        t2 = time.time()\n",
    "        metric_seq_time = t2-t1\n",
    "        print(\"metric time  \"+ str(metric_seq_time))\n",
    "        \n",
    "        pearson_seq = metric_seq.result()[\"PearsonR\"].numpy()\n",
    "        batch_validation = {\"sequence\": batch[\"sequence\"],\n",
    "                            \"target\": batch[\"target\"],\n",
    "                            \"interval\": batch[\"interval\"],\n",
    "                            \"PearsonR\": pearson_seq}\n",
    "        dataset_197k_evaluation.append(batch_validation)\n",
    "        \n",
    "        \n",
    "        t3 = time.time()\n",
    "        object_time = t3-t2\n",
    "        print(\"object time  \"+ str(object_time))\n",
    "\n",
    "\n",
    "    return dataset_197k_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f7abbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.]]], dtype=float32)>,\n",
       " 'target': <tf.Tensor: shape=(896, 5313), dtype=float32, numpy=\n",
       " array([[0.        , 0.        , 0.        , ..., 0.        , 0.1184082 ,\n",
       "         0.        ],\n",
       "        [0.00741959, 0.00526428, 0.        , ..., 0.        , 0.02198792,\n",
       "         0.00336266],\n",
       "        [0.00865936, 0.02127075, 0.01722717, ..., 0.        , 0.        ,\n",
       "         0.06109619],\n",
       "        ...,\n",
       "        [0.03768921, 0.04833984, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.04605103, 0.08355713, 0.01335907, ..., 0.        , 0.        ,\n",
       "         0.11633301],\n",
       "        [0.06158447, 0.08026123, 0.06018066, ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32)>,\n",
       " 'interval': Interval(chrom='chrX', start=55044496, end=55175568, name='', strand='.', ...)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_197k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a2cd2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predtime 17.722840309143066\n",
      "metric time  0.029781818389892578\n",
      "object time  0.0013587474822998047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       "  array([[[1., 0., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.],\n",
       "          [0., 0., 0., 1.]]], dtype=float32)>,\n",
       "  'target': <tf.Tensor: shape=(896, 5313), dtype=float32, numpy=\n",
       "  array([[0.        , 0.        , 0.        , ..., 0.        , 0.1184082 ,\n",
       "          0.        ],\n",
       "         [0.00741959, 0.00526428, 0.        , ..., 0.        , 0.02198792,\n",
       "          0.00336266],\n",
       "         [0.00865936, 0.02127075, 0.01722717, ..., 0.        , 0.        ,\n",
       "          0.06109619],\n",
       "         ...,\n",
       "         [0.03768921, 0.04833984, 0.        , ..., 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.04605103, 0.08355713, 0.01335907, ..., 0.        , 0.        ,\n",
       "          0.11633301],\n",
       "         [0.06158447, 0.08026123, 0.06018066, ..., 0.        , 0.        ,\n",
       "          0.        ]], dtype=float32)>,\n",
       "  'interval': Interval(chrom='chrX', start=55044496, end=55175568, name='', strand='.', ...),\n",
       "  'PearsonR': array([0.928051  , 0.92224   , 0.78818774, ..., 0.05206543, 0.19001374,\n",
       "         0.1243078 ], dtype=float32)}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_all_sequences_mod(model,\n",
    "                               dataset=test_ds,\n",
    "                               head=\"human\",\n",
    "                               dataset_197k_evaluation = [], \n",
    "                               max_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c98078c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_ds):\n",
    "    return evaluate_model_all_sequences_mod(model,\n",
    "                               dataset=test_ds,\n",
    "                               head=\"human\",\n",
    "                               dataset_197k_evaluation = [], \n",
    "                               max_steps=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12e70652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-51:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'evaluate_model' on <module '__main__'>\n",
      "Process ForkPoolWorker-50:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dbe88cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5cd6ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_seq(model, batch, head, max_steps=None):\n",
    "     \n",
    "    prediction = predict(batch['sequence'])\n",
    "    metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    metric_seq.update_state(batch['target'][np.newaxis], prediction)        \n",
    "    pearson_seq = metric_seq.result()[\"PearsonR\"].numpy()\n",
    "    batch_validation = {\"sequence\": batch[\"sequence\"],\n",
    "                            \"target\": batch[\"target\"],\n",
    "                            \"interval\": batch[\"interval\"],\n",
    "                            \"PearsonR\": pearson_seq}\n",
    "\n",
    "    return batch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65cfc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list([test_ds, test_ds, test_ds, test_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01f49bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'sequence': <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       "   array([[[1., 0., 0., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.]]], dtype=float32)>,\n",
       "   'target': <tf.Tensor: shape=(896, 5313), dtype=float32, numpy=\n",
       "   array([[0.        , 0.        , 0.        , ..., 0.        , 0.1184082 ,\n",
       "           0.        ],\n",
       "          [0.00741959, 0.00526428, 0.        , ..., 0.        , 0.02198792,\n",
       "           0.00336266],\n",
       "          [0.00865936, 0.02127075, 0.01722717, ..., 0.        , 0.        ,\n",
       "           0.06109619],\n",
       "          ...,\n",
       "          [0.03768921, 0.04833984, 0.        , ..., 0.        , 0.        ,\n",
       "           0.        ],\n",
       "          [0.04605103, 0.08355713, 0.01335907, ..., 0.        , 0.        ,\n",
       "           0.11633301],\n",
       "          [0.06158447, 0.08026123, 0.06018066, ..., 0.        , 0.        ,\n",
       "           0.        ]], dtype=float32)>,\n",
       "   'interval': Interval(chrom='chrX', start=55044496, end=55175568, name='', strand='.', ...)}],\n",
       " [{'sequence': <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       "   array([[[1., 0., 0., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.]]], dtype=float32)>,\n",
       "   'target': <tf.Tensor: shape=(896, 5313), dtype=float32, numpy=\n",
       "   array([[0.        , 0.        , 0.        , ..., 0.        , 0.1184082 ,\n",
       "           0.        ],\n",
       "          [0.00741959, 0.00526428, 0.        , ..., 0.        , 0.02198792,\n",
       "           0.00336266],\n",
       "          [0.00865936, 0.02127075, 0.01722717, ..., 0.        , 0.        ,\n",
       "           0.06109619],\n",
       "          ...,\n",
       "          [0.03768921, 0.04833984, 0.        , ..., 0.        , 0.        ,\n",
       "           0.        ],\n",
       "          [0.04605103, 0.08355713, 0.01335907, ..., 0.        , 0.        ,\n",
       "           0.11633301],\n",
       "          [0.06158447, 0.08026123, 0.06018066, ..., 0.        , 0.        ,\n",
       "           0.        ]], dtype=float32)>,\n",
       "   'interval': Interval(chrom='chrX', start=55044496, end=55175568, name='', strand='.', ...)}],\n",
       " [{'sequence': <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       "   array([[[1., 0., 0., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.]]], dtype=float32)>,\n",
       "   'target': <tf.Tensor: shape=(896, 5313), dtype=float32, numpy=\n",
       "   array([[0.        , 0.        , 0.        , ..., 0.        , 0.1184082 ,\n",
       "           0.        ],\n",
       "          [0.00741959, 0.00526428, 0.        , ..., 0.        , 0.02198792,\n",
       "           0.00336266],\n",
       "          [0.00865936, 0.02127075, 0.01722717, ..., 0.        , 0.        ,\n",
       "           0.06109619],\n",
       "          ...,\n",
       "          [0.03768921, 0.04833984, 0.        , ..., 0.        , 0.        ,\n",
       "           0.        ],\n",
       "          [0.04605103, 0.08355713, 0.01335907, ..., 0.        , 0.        ,\n",
       "           0.11633301],\n",
       "          [0.06158447, 0.08026123, 0.06018066, ..., 0.        , 0.        ,\n",
       "           0.        ]], dtype=float32)>,\n",
       "   'interval': Interval(chrom='chrX', start=55044496, end=55175568, name='', strand='.', ...)}],\n",
       " [{'sequence': <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       "   array([[[1., 0., 0., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           [0., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.],\n",
       "           [0., 0., 0., 1.]]], dtype=float32)>,\n",
       "   'target': <tf.Tensor: shape=(896, 5313), dtype=float32, numpy=\n",
       "   array([[0.        , 0.        , 0.        , ..., 0.        , 0.1184082 ,\n",
       "           0.        ],\n",
       "          [0.00741959, 0.00526428, 0.        , ..., 0.        , 0.02198792,\n",
       "           0.00336266],\n",
       "          [0.00865936, 0.02127075, 0.01722717, ..., 0.        , 0.        ,\n",
       "           0.06109619],\n",
       "          ...,\n",
       "          [0.03768921, 0.04833984, 0.        , ..., 0.        , 0.        ,\n",
       "           0.        ],\n",
       "          [0.04605103, 0.08355713, 0.01335907, ..., 0.        , 0.        ,\n",
       "           0.11633301],\n",
       "          [0.06158447, 0.08026123, 0.06018066, ..., 0.        , 0.        ,\n",
       "           0.        ]], dtype=float32)>,\n",
       "   'interval': Interval(chrom='chrX', start=55044496, end=55175568, name='', strand='.', ...)}]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "165e3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrt(inp):\n",
    "    return(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d60cea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_seq(model, batch, head, max_steps=None):\n",
    "    \n",
    "    prediction = predict(batch['sequence'])\n",
    "    metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    metric_seq.update_state(batch['target'][np.newaxis], prediction)        \n",
    "    pearson_seq = metric_seq.result()[\"PearsonR\"].numpy()\n",
    "    batch_validation = {\"sequence\": batch[\"sequence\"],\n",
    "                            \"target\": batch[\"target\"],\n",
    "                            \"interval\": batch[\"interval\"],\n",
    "                            \"PearsonR\": pearson_seq}\n",
    "\n",
    "    return batch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5b533a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils_full.Enformer at 0x7f1c1c3bfb80>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "24b75b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_seq(model, batch):\n",
    "    \n",
    "    def predict(x, model, head):\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "    prediction = predict(batch['sequence'])\n",
    "    metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    metric_seq.update_state(batch['target'][np.newaxis], prediction)        \n",
    "    pearson_seq = metric_seq.result()[\"PearsonR\"].numpy()\n",
    "    batch_validation = {\"sequence\": batch[\"sequence\"],\n",
    "                            \"target\": batch[\"target\"],\n",
    "                            \"interval\": batch[\"interval\"],\n",
    "                            \"PearsonR\": pearson_seq}\n",
    "\n",
    "    return batch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b24e08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_2(batch):\n",
    "     \n",
    "    prediction = batch['sequence']\n",
    "    metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    metric_seq.update_state(batch['target'][np.newaxis], prediction)  \n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "956e856e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Loader._recreate_base_user_object.<locals>._UserObject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_411010/3740540200.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 2: `pool.apply` the `howmany_within_range()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_411010/3740540200.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 2: `pool.apply` the `howmany_within_range()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mPool\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mrunning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         '''\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'Loader._recreate_base_user_object.<locals>._UserObject'"
     ]
    }
   ],
   "source": [
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "results = [pool.apply(evaluate_model_seq, args=(model, example, \"human\")) for example in a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "835c5a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.]]], dtype=float32)>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e611df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 3, 1, 3, 2, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "results = [pool.apply(howmany_within_range, args=(row, 4, 8)) for row in data]\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()    \n",
    "\n",
    "print(results[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59b64de0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_411010/528207233.py\", line 2, in test\n    return evaluate_model_all_sequences_mod(model,\n  File \"/tmp/ipykernel_411010/2149349230.py\", line 13, in evaluate_model_all_sequences_mod\n    batch = dataset[i]\nKeyError: 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_411010/1501508461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "pool.map(test, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
