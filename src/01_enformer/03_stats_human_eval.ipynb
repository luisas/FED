{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed624904",
   "metadata": {},
   "source": [
    "# Enformer human validation (smaller dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5383c",
   "metadata": {},
   "source": [
    "## Evaluate sequence-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bf277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../../../../data/FED\"\n",
    "outputdir = os.path.join(datadir, \"hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc021646",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(outputdir,'dataset_197k_evaluation_50.h5')\n",
    "with open(file, 'rb') as config_dictionary_file:\n",
    "    dataset_197k_evaluation = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e780aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(outputdir,'summarized_metrics.h5')\n",
    "with open(file, 'rb') as config_dictionary_file:\n",
    "    summarized_metrics = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc991fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download targets from Basenji2 dataset \n",
    "# Cite: Kelley et al Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\n",
    "targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
    "df_targets = pd.read_csv(targets_txt, sep='\\t')\n",
    "df_targets\n",
    "\n",
    "suppl = pd.ExcelFile(os.path.join(datadir, \"enformer_suppl.xlsx\"))\n",
    "print(suppl.sheet_names)\n",
    "suppl_human = suppl.parse(suppl.sheet_names[1])\n",
    "suppl_mouse = suppl.parse(suppl.sheet_names[2])\n",
    "suppl_human[\"organism\"] = \"human\"\n",
    "suppl_mouse[\"organism\"] = \"mouse\"\n",
    "frames = [suppl_human, suppl_mouse]\n",
    "suppl_df = pd.concat(frames)\n",
    "\n",
    "\n",
    "file = os.path.join(outputdir,'suppl_df.h5')\n",
    "with open(file, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(suppl_df, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a978247",
   "metadata": {},
   "source": [
    "# Plot sequences summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_assays = suppl_df[suppl_df[\"organism\"] == \"human\"][\"assay_type\"]\n",
    "ordered_assays_full = suppl_df[suppl_df[\"organism\"] == \"human\"][\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f65dff",
   "metadata": {},
   "source": [
    "### How many tracks per assay type? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(suppl_df[suppl_df[\"organism\"] == \"human\"].groupby(\"assay_type\").count()[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23504148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_evaluation_df(i,dataset_197k_evaluation, ordered_assays ):\n",
    "    # Create dataframe for plotting\n",
    "    df = pd.DataFrame()\n",
    "    # Add sequence\n",
    "    df[\"sequence\"] = np.repeat(i,len(ordered_assays))\n",
    "    # Add assay\n",
    "    df[\"assay\"] = ordered_assays\n",
    "    df[\"full\"] = ordered_assays_full\n",
    "    # Add pearson values \n",
    "    df[\"pearson\"] = (dataset_197k_evaluation[i][\"PearsonR\"])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb09fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_197k_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "for i in range(50):\n",
    "    df = get_sequence_evaluation_df(i,dataset_197k_evaluation, ordered_assays)\n",
    "    print(i)\n",
    "    final_df = pd.concat([final_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36568adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df[(final_df[\"assay\"]  == \"DNASE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c48bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"assay\", style=\"time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"sequence\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "# Load the example tips dataset\n",
    "sns.violinplot(x=\"assay\", y=\"pearson\",  palette=\"mako\", data=final_df)\n",
    "\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3036dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().time() # time object\n",
    "\n",
    "print(\"now =\", now)\n",
    "print(\"type(now) =\", type(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(data=final_df, x=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ecc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous validation dictionary\n",
    "enformer_dict_file = os.path.join(outputdir,'00_enformer_dict_seqs.h5')\n",
    "\n",
    "with open(enformer_dict_file, 'rb') as config_dictionary_file:\n",
    "    human_validation_dict = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe702d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_validation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fafb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- OLD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd0b39",
   "metadata": {},
   "source": [
    "### PLOT: Distributions of pearson correlation coefficients per assay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the values are in order of assay (TODO check) \n",
    "assay_list = list(suppl_df[\"assay_type\"])\n",
    "pearson_per_assay = list(metrics_human[0][\"PearsonR\"].numpy())\n",
    "data_tuples = list(zip(assay_list,pearson_per_assay))\n",
    "df_pearson_assay = pd.DataFrame(data_tuples, columns=['assay','pearson'])\n",
    "df_pearson_assay[\"pearson\"]\n",
    "df = df_pearson_assay\n",
    "df = df.astype({\"assay\": str, \"pearson\": float})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"assay\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bdad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "# Load the example tips dataset\n",
    "\n",
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.violinplot(x=\"assay\", y=\"pearson\",  palette=\"mako\", linewidth=1.5,\n",
    "            data=df)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ad2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Initialize \n",
    "g = sns.FacetGrid(df, row=\"assay\", hue=\"assay\", aspect=15, height=1, palette=\"mako\")\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"pearson\",\n",
    "      bw_adjust=.5, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"pearson\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "g.map(label, \"pearson\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.3)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a693d",
   "metadata": {},
   "source": [
    "# OLD (do not delete) - prepare  dictionary intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dd801",
   "metadata": {},
   "source": [
    "## Check if the sequences are in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9bca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(human_sequences, memory_map=True, header=None, index_col=False, delimiter=\"\\t\")\n",
    "# keep only validation intervals \n",
    "validation_intervals= df[df[3]==\"valid\"]\n",
    "#validation_intervals = validation_intervals.head()\n",
    "# create list with interval\n",
    "interval_list = list()\n",
    "validation_intervals.apply(lambda row : interval_list.append(kipoiseq.Interval(row[0],row[1], row[2])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for search (can be improved! quite slow)\n",
    "human_validation_dict = {}\n",
    "for interval in interval_list: \n",
    "    sequence = one_hot_encode(fasta_extractor.extract(interval))\n",
    "    human_validation_dict[interval] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pickle\n",
    "\n",
    "enformer_dict_file = os.path.join(outputdir,'00_enformer_dict_seqs.h5')\n",
    "# Step 2\n",
    "with open(enformer_dict_file, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(human_validation_dict, config_dictionary_file)\n",
    "    \n",
    "# -------- read -------\n",
    "with open(enformer_dict_file, 'rb') as config_dictionary_file:\n",
    "    config_dictionary = pickle.load(config_dictionary_file)\n",
    "\n",
    "print(config_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df517ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../../../../data/FED\"\n",
    "outputdir = os.path.join(datadir, \"basenji/human/\")\n",
    "enformer_dict_file = os.path.join(outputdir,'00_enformer_dict_seqs_human.h5')\n",
    "# -------- read -------\n",
    "with open(enformer_dict_file, 'rb') as config_dictionary_file:\n",
    "    config_dictionary = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02bb3469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2213"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config_dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2761e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(chrom='chr6', start=165740202, end=165871274, name='', strand='.', ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(config_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b29151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dictionary[next(iter(config_dictionary))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9eb58",
   "metadata": {},
   "source": [
    "### Same with mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e04900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6eb45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_sequences = \"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/mouse/mouse_sequences.bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a7b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"/home/luisasantus/Desktop/crg_cluster/data/FED/hg38.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(mouse_sequences, memory_map=True, header=None, index_col=False, delimiter=\"\\t\")\n",
    "# keep only validation intervals \n",
    "validation_intervals= df[df[3]==\"valid\"]\n",
    "#validation_intervals = validation_intervals.head()\n",
    "# create list with interval\n",
    "interval_list = list()\n",
    "validation_intervals.apply(lambda row : interval_list.append(kipoiseq.Interval(row[0],row[1], row[2])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ff95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence):\n",
    "    return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastaStringExtractor:\n",
    "\n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "\n",
    "def get_metadata(metadata):\n",
    "    with tf.io.gfile.GFile(metadata, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_dataset(tfr, metadata):\n",
    "\n",
    "    metadata = get_metadata(metadata)\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord, compression_type='ZLIB')\n",
    "\n",
    "    dataset = dataset.map(functools.partial(deserialize, metadata=metadata))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "fasta_extractor = FastaStringExtractor(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13557e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for search (can be improved! quite slow)\n",
    "mouse_validation_dict = {}\n",
    "for interval in interval_list: \n",
    "    sequence = one_hot_encode(fasta_extractor.extract(interval))\n",
    "    mouse_validation_dict[interval] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = \"/home/luisasantus/Desktop/crg_cluster/data/FED/basenji/mouse\"\n",
    "\n",
    "enformer_dict_file = os.path.join(outputdir,'00_enformer_dict_seqs_mouse.h5')\n",
    "# Step 2\n",
    "with open(enformer_dict_file, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(mouse_validation_dict, config_dictionary_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0490d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../../../../data/FED\"\n",
    "outputdir = os.path.join(datadir, \"basenji/mouse/\")\n",
    "enformer_dict_file = os.path.join(outputdir,'00_enformer_dict_seqs_mouse.h5')\n",
    "# -------- read -------\n",
    "with open(enformer_dict_file, 'rb') as config_dictionary_file:\n",
    "    config_dictionary = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82a2313c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131072, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dictionary[next(iter(config_dictionary))].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b16199",
   "metadata": {},
   "source": [
    "## Quick test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "828836ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 15:51:55.270635: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-07 15:51:55.270655: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-02-07 15:51:57.701050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-07 15:51:57.701084: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-07 15:51:57.701099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (luisasantus-HP-EliteDesk-800-G5-TWR): /proc/driver/nvidia/version does not exist\n",
      "2022-02-07 15:51:57.701475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "file = os.path.join(\"/home/luisasantus/Desktop/crg_cluster/data/FED/enformer/human/pred_standard/valid-0-6_197k_pred.pkl\")\n",
    "with open(file, 'rb') as config_dictionary_file:\n",
    "    pred = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ec22c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': <tf.Tensor: shape=(1, 196608, 4), dtype=float32, numpy=\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.]]], dtype=float32)>,\n",
       " 'target': <tf.Tensor: shape=(896, 5313), dtype=float32, numpy=\n",
       " array([[0.0043602 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00084496, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00675964, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.07727051, 0.03848267, 0.02961731, ..., 0.07946777, 0.16455078,\n",
       "         0.1340332 ],\n",
       "        [0.0302887 , 0.05227661, 0.0186615 , ..., 0.        , 0.81933594,\n",
       "         0.        ],\n",
       "        [0.02532959, 0.01405334, 0.00772476, ..., 0.        , 0.14233398,\n",
       "         0.22802734]], dtype=float32)>,\n",
       " 'interval': Interval(chrom='chrX', start=24088313, end=24219385, name='', strand='.', ...),\n",
       " 'PearsonR': array([0.81257886, 0.92487174, 0.8000129 , ..., 0.85583717, 0.97051615,\n",
       "        0.9650185 ], dtype=float32)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b083c8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>assay</th>\n",
       "      <th>pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DNase/cerebellum male adult (27 years) and mal...</td>\n",
       "      <td>0.684329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>DNase/frontal cortex male adult (27 years) and...</td>\n",
       "      <td>0.783626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>DNase/chorion</td>\n",
       "      <td>0.622130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>DNase/Ishikawa treated with 0.02% dimethyl sul...</td>\n",
       "      <td>0.764103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DNase/GM03348</td>\n",
       "      <td>0.885546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15934</th>\n",
       "      <td>2</td>\n",
       "      <td>CAGE/epithelioid sarcoma cell line:HS-ES-2R</td>\n",
       "      <td>-0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15935</th>\n",
       "      <td>2</td>\n",
       "      <td>CAGE/squamous cell lung carcinoma cell line:RE...</td>\n",
       "      <td>0.024904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>2</td>\n",
       "      <td>CAGE/gastric cancer cell line:GSS</td>\n",
       "      <td>0.018539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15937</th>\n",
       "      <td>2</td>\n",
       "      <td>CAGE/carcinoid cell line:NCI-H727</td>\n",
       "      <td>0.136828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15938</th>\n",
       "      <td>2</td>\n",
       "      <td>CAGE/lung adenocarcinoma, papillary cell line:...</td>\n",
       "      <td>0.084035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15939 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence                                              assay   pearson\n",
       "0             0  DNase/cerebellum male adult (27 years) and mal...  0.684329\n",
       "1             0  DNase/frontal cortex male adult (27 years) and...  0.783626\n",
       "2             0                                      DNase/chorion  0.622130\n",
       "3             0  DNase/Ishikawa treated with 0.02% dimethyl sul...  0.764103\n",
       "4             0                                      DNase/GM03348  0.885546\n",
       "...         ...                                                ...       ...\n",
       "15934         2        CAGE/epithelioid sarcoma cell line:HS-ES-2R -0.007207\n",
       "15935         2  CAGE/squamous cell lung carcinoma cell line:RE...  0.024904\n",
       "15936         2                  CAGE/gastric cancer cell line:GSS  0.018539\n",
       "15937         2                  CAGE/carcinoid cell line:NCI-H727  0.136828\n",
       "15938         2  CAGE/lung adenocarcinoma, papillary cell line:...  0.084035\n",
       "\n",
       "[15939 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets = pd.read_csv(\"/home/luisasantus/Desktop/crg_cluster/data/FED/enformer/human/pred_standard/summarydf/valid-0-2_197k_pred_eval_df.csv\")\n",
    "df_targets"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
