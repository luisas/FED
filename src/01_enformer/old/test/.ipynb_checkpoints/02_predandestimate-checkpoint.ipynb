{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed624904",
   "metadata": {},
   "source": [
    "# Enformer human validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbf0ab",
   "metadata": {},
   "source": [
    "### Load  pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba173e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 11:32:34.416771: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-02 11:32:34.416791: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "import pyfaidx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import importlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1af4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoiseq\n",
    "from kipoiseq import Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5f7cc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_107579/141982676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_utils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspec_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "spec_utils = importlib.util.spec_from_file_location(\"utils\", os.path.join(os.getcwd() ,\"../utils/utils.py\"))\n",
    "utils = importlib.util.module_from_spec(spec_utils)\n",
    "spec_utils.loader.exec_module(utils)\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb9edb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleSpec(name='utils', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f5311c40f40>, origin='/home/luisasantus/Desktop/crg_cluster/projects/FED/src/01_enformer/test/../utils/utils.py')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6254a",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0900f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FastaNotFoundError",
     "evalue": "Cannot read FASTA file ../../../../data/FED/hg38.fa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyfaidx/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, default_seq, key_function, as_raw, strict_bounds, read_ahead, mutable, split_char, duplicate_action, filt_function, one_based_attributes, read_long_names, sequence_always_upper, rebuild, build_index)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             self.file = self._fasta_opener(filename, 'r+b'\n\u001b[0m\u001b[1;32m    375\u001b[0m                                            if mutable else 'rb')\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../data/FED/hg38.fa'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFastaNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_107579/3356477893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfasta_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hg38.fa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhuman_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_human_sequences.bed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpyfaidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaidx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyfaidx/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, default_seq, key_function, as_raw, strict_bounds, read_ahead, mutable, split_char, duplicate_action, filt_function, one_based_attributes, read_long_names, sequence_always_upper, rebuild, build_index)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \"compress your FASTA.\")\n\u001b[1;32m    382\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                 raise FastaNotFoundError(\n\u001b[0m\u001b[1;32m    384\u001b[0m                     \"Cannot read FASTA file %s\" % filename)\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFastaNotFoundError\u001b[0m: Cannot read FASTA file ../../../../data/FED/hg38.fa"
     ]
    }
   ],
   "source": [
    "model_path = 'https://tfhub.dev/deepmind/enformer/1'\n",
    "datadir = \"../../../../data/FED\"\n",
    "outputdir = os.path.join(datadir, \"hd5\")\n",
    "fasta_file = os.path.join(datadir, \"hg38.fa\")\n",
    "human_sequences = os.path.join(datadir, \"data_human_sequences.bed\")\n",
    "pyfaidx.Faidx(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91386fb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils' has no attribute 'Enformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_107042/1548740589.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'Enformer'"
     ]
    }
   ],
   "source": [
    "model = utils.Enformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import enformer.py as module\n",
    "spec = importlib.util.spec_from_file_location(\"enformer\", os.path.join(os.getcwd() ,\"utils/enformer.py\"))\n",
    "enformer = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(enformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c542b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from utils.enformer import * \n",
    "    from utils.utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e380ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_extractor = utils.FastaStringExtractor(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7eb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous validation dictionary\n",
    "dataset_197k_file = os.path.join(outputdir,'test_197k_valid.h5')\n",
    "\n",
    "with open(dataset_197k_file, 'rb') as config_dictionary_file:\n",
    "    dataset_197k = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d206fba",
   "metadata": {},
   "source": [
    "# Evaluate per track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4028ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGHT = 393_216\n",
    "## pad the sequence with Ns (anyways ignored by the model)\n",
    "def pad_one_hot(sequence_one_hot, NEW_SIZE):\n",
    "    ADD_ENDS = int((NEW_SIZE - sequence_one_hot.shape[0])/2)\n",
    "    pad_zero = np.tile(np.array([0., 0., 0., 0.]), (ADD_ENDS, 1))\n",
    "    padded_left = np.append(pad_zero,sequence_one_hot, axis=0)\n",
    "    pad_sequence = np.append(padded_left,pad_zero, axis=0)\n",
    "    return(pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcd040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences_mod(model, dataset, head, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    \n",
    "    # Given a tensor with a one-encoded sequence, predicts head tracks\n",
    "    def predict(x):\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "    \n",
    "    i = 0 \n",
    "    for i, batch in enumerate(dataset_197k): \n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        i = i+1\n",
    "        prediction = predict(batch['sequence'])\n",
    "        metric.update_state(batch['target'], prediction)\n",
    "\n",
    "    return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dataset_197k_evaluation = copy.deepcopy(dataset_197k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences_mod(model, dataset, head, dataset_197k_evaluation, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    \n",
    "    # Given a tensor with a one-encoded sequence, predicts head tracks\n",
    "    def predict(x):\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "    \n",
    "    for i, batch in enumerate(dataset_197k): \n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        \n",
    "        prediction = predict(batch['sequence'])\n",
    "        metric.update_state(batch['target'], prediction)\n",
    "        \n",
    "        # Compute it on a sequence basis\n",
    "        metric_seq = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "        metric_seq.update_state(batch['target'], prediction)\n",
    "        dataset_197k_evaluation[i][\"PearsonR\"] = metric.result()[\"PearsonR\"].numpy()\n",
    "        print(dataset_197k_evaluation[i][\"PearsonR\"])\n",
    "        i = i+1\n",
    "    return list([metric.result(), dataset_197k_evaluation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_human = evaluate_model_all_sequences_mod(model,\n",
    "                               dataset=dataset_197k[0:1],\n",
    "                               head='human',\n",
    "                               dataset_197k_evaluation = dataset_197k_evaluation,\n",
    "                               max_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3363a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_197k_evaluation[0][\"PearsonR\"] = dataset_197k_evaluation[1][\"PearsonR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a978247",
   "metadata": {},
   "source": [
    "# Plot sequences summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_assays = suppl_df[suppl_df[\"organism\"] == \"human\"][\"assay_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c586822",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(suppl_df[suppl_df[\"organism\"] == \"human\"].groupby(\"assay_type\").count()[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23504148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_evaluation_df(i,dataset_197k_evaluation, ordered_assays ):\n",
    "    # Create dataframe for plotting\n",
    "    df = pd.DataFrame()\n",
    "    # Add sequence\n",
    "    df[\"sequence\"] = np.repeat(1,len(ordered_assays))\n",
    "    # Add assay\n",
    "    df[\"assay\"] = ordered_assays\n",
    "    # Add pearson values \n",
    "    df[\"pearson\"] = (dataset_197k_evaluation[i][\"PearsonR\"])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "for i in range(len(dataset_197k_evaluation)):\n",
    "    df = get_sequence_evaluation_df(i,dataset_197k_evaluation, ordered_assays)\n",
    "    print(i)\n",
    "    final_df = pd.concat([final_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "# Load the example tips dataset\n",
    "\n",
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.boxplot(x=\"assay\", y=\"pearson\",  palette=\"mako\",\n",
    "            data=final_df)\n",
    "\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168c3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ecc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8d2f5d7",
   "metadata": {},
   "source": [
    "### Check tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download targets from Basenji2 dataset \n",
    "# Cite: Kelley et al Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\n",
    "targets_txt = 'https://raw.githubusercontent.com/calico/basenji/master/manuscripts/cross2020/targets_human.txt'\n",
    "df_targets = pd.read_csv(targets_txt, sep='\\t')\n",
    "df_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fcffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppl = pd.ExcelFile(os.path.join(datadir, \"enformer_suppl.xlsx\"))\n",
    "print(suppl.sheet_names)\n",
    "suppl_human = suppl.parse(suppl.sheet_names[1])\n",
    "suppl_mouse = suppl.parse(suppl.sheet_names[2])\n",
    "suppl_human[\"organism\"] = \"human\"\n",
    "suppl_mouse[\"organism\"] = \"mouse\"\n",
    "frames = [suppl_human, suppl_mouse]\n",
    "suppl_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c5b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f917fd13",
   "metadata": {},
   "source": [
    "### compute score (how well predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21187f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "#1 - retrieve the 197k sequence instead o 131k \n",
    "prefix = \"gs://basenji_barnyard/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a615e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dataset = get_dataset('human', 'valid', prefix).batch(1).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06daf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(human_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences(model, dataset, head, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    print(\"Metric dictionary created\")\n",
    "    \n",
    "    def predict(x):\n",
    "        print(\"Beginning prediction\")\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "    print(\"Predict funciton loaded\")\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(dataset)):\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        prediction = predict(batch['sequence'])\n",
    "        metric.update_state(batch['target'], prediction)\n",
    "\n",
    "    return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on first ten \n",
    "# Right now it evaluates the whole model and \n",
    "metrics_human = evaluate_model_all_sequences(model,\n",
    "                               dataset=get_dataset('human', 'valid').batch(1).prefetch(2),\n",
    "                               head='human',\n",
    "                               max_steps=2)\n",
    "#print('')dataset_197k\n",
    "#print({k: v.numpy().mean() for k, v in metrics_human.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_all_sequences(model, sequence_dict, head, max_steps=None):\n",
    "    \n",
    "    metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "    print(\"Metric dictionary created\")\n",
    "    \n",
    "    def predict(x):\n",
    "        print(\"Beginning prediction\")\n",
    "        padded_sequence = pad_one_hot(np.squeeze(x.numpy(), axis=0), SEQUENCE_LENGHT)[np.newaxis]\n",
    "        predictions = model.predict_on_batch(padded_sequence)[head]\n",
    "        return tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "    print(\"Predict funciton loaded\")\n",
    "    \n",
    "    i = 0 \n",
    "    for keys in sequence_dict.keys():\n",
    "        if max_steps is not None and i > max_steps:\n",
    "            break\n",
    "        i = i+1\n",
    "        prediction = predict(sequence_dict['sequence'])\n",
    "        metric.update_state(sequence_dict['target'], prediction)\n",
    "\n",
    "    return metric.result()\n",
    "\n",
    "\n",
    "\n",
    "metrics_human = evaluate_model_all_sequences(model,\n",
    "                               dataset= dataset_197k,\n",
    "                               head='human',\n",
    "                               max_steps=2)\n",
    "#print('')dataset_197k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd0b39",
   "metadata": {},
   "source": [
    "### PLOT: Distributions of pearson correlation coefficients per assay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the values are in order of assay (TODO check) \n",
    "assay_list = list(suppl_df[\"assay_type\"])\n",
    "pearson_per_assay = list(metrics_human[0][\"PearsonR\"].numpy())\n",
    "data_tuples = list(zip(assay_list,pearson_per_assay))\n",
    "df_pearson_assay = pd.DataFrame(data_tuples, columns=['assay','pearson'])\n",
    "df_pearson_assay[\"pearson\"]\n",
    "df = df_pearson_assay\n",
    "df = df.astype({\"assay\": str, \"pearson\": float})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"assay\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "# Load the example tips dataset\n",
    "\n",
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.violinplot(x=\"assay\", y=\"pearson\",  palette=\"mako\", linewidth=1.5,\n",
    "            data=df)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ad2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Initialize \n",
    "g = sns.FacetGrid(df, row=\"assay\", hue=\"assay\", aspect=15, height=1, palette=\"mako\")\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"pearson\",\n",
    "      bw_adjust=.5, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"pearson\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "g.map(label, \"pearson\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.3)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a693d",
   "metadata": {},
   "source": [
    "# OLD (do not delete) - prepare  dictionary intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dd801",
   "metadata": {},
   "source": [
    "## Check if the sequences are in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9bca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(human_sequences, memory_map=True, header=None, index_col=False, delimiter=\"\\t\")\n",
    "# keep only validation intervals \n",
    "validation_intervals= df[df[3]==\"valid\"]\n",
    "#validation_intervals = validation_intervals.head()\n",
    "# create list with interval\n",
    "interval_list = list()\n",
    "validation_intervals.apply(lambda row : interval_list.append(kipoiseq.Interval(row[0],row[1], row[2])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for search (can be improved! quite slow)\n",
    "human_validation_dict = {}\n",
    "for interval in interval_list: \n",
    "    sequence = one_hot_encode(fasta_extractor.extract(interval))\n",
    "    human_validation_dict[interval] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pickle\n",
    "\n",
    "enformer_dict_file = os.path.join(outputdir,'00_enformer_dict_seqs.h5')\n",
    "# Step 2\n",
    "with open(enformer_dict_file, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(human_validation_dict, config_dictionary_file)\n",
    "    \n",
    "# -------- read -------\n",
    "with open(enformer_dict_file, 'rb') as config_dictionary_file:\n",
    "    config_dictionary = pickle.load(config_dictionary_file)\n",
    "\n",
    "print(config_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b376d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a61886",
   "metadata": {},
   "source": [
    "## Convert Human dataset into list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dataset_list = []\n",
    "for i, batch in tqdm(enumerate(human_dataset)):\n",
    "    human_dataset_list.append(batch)\n",
    "\n",
    "file = os.path.join(outputdir,'human_dataset.h5')\n",
    "\n",
    "# Step 2\n",
    "with open(file, 'wb') as config_dictionary_file:\n",
    "    pickle.dump(human_dataset_list, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b122d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548d022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
